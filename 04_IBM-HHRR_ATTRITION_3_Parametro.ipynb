{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fde37f8",
   "metadata": {},
   "source": [
    "# 02_IBM-HHRR_ATTRITION_Parametro_v3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf3ebe",
   "metadata": {},
   "source": [
    "## Previous Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24322906",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb7744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML  \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import  f1_score, fbeta_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992267cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define general path:\n",
    "path_general = r'C:\\HHRR'\n",
    "path_total = os.path.join(path_general,'01_total_models') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a25c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Libraries.\n",
    "\n",
    "# Cross validation\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "#------------- / Regresion Logistica /--------------\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#--------------/ XGBoost /--------------------------\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#-------------/ AdaBoost /--------------------------\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#-------------/ CatBoost /--------------------------\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#------------/ Decission Tree /----------------------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#------------/ Random Forest /-----------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#-----------/   MLP /--------------------------------\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#------------/ KNN /----------------------------------\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#------------/ Naive - Bayes /-------------------------\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070412a2",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65eada4-0a02-49b6-a030-6302aed10a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessTravel_Non-Travel</th>\n",
       "      <th>BusinessTravel_Travel_Frequently</th>\n",
       "      <th>BusinessTravel_Travel_Rarely</th>\n",
       "      <th>Department_Human Resources</th>\n",
       "      <th>Department_Research &amp; Development</th>\n",
       "      <th>Department_Sales</th>\n",
       "      <th>Education_Associate Degree</th>\n",
       "      <th>Education_Bachelorâ€™s Degree</th>\n",
       "      <th>Education_Doctorate</th>\n",
       "      <th>Education_High School</th>\n",
       "      <th>...</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>annual_salary</th>\n",
       "      <th>economic_impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>71916</td>\n",
       "      <td>14670.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>61560</td>\n",
       "      <td>12558.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25080</td>\n",
       "      <td>4037.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34908</td>\n",
       "      <td>6876.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41616</td>\n",
       "      <td>8198.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30852</td>\n",
       "      <td>6077.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>119892</td>\n",
       "      <td>25177.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>73704</td>\n",
       "      <td>15035.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>64680</td>\n",
       "      <td>13194.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>52848</td>\n",
       "      <td>10780.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BusinessTravel_Non-Travel  BusinessTravel_Travel_Frequently  \\\n",
       "0                           0.0                               0.0   \n",
       "1                           0.0                               1.0   \n",
       "2                           0.0                               0.0   \n",
       "3                           0.0                               1.0   \n",
       "4                           0.0                               0.0   \n",
       "...                         ...                               ...   \n",
       "1465                        0.0                               1.0   \n",
       "1466                        0.0                               0.0   \n",
       "1467                        0.0                               0.0   \n",
       "1468                        0.0                               1.0   \n",
       "1469                        0.0                               0.0   \n",
       "\n",
       "      BusinessTravel_Travel_Rarely  Department_Human Resources  \\\n",
       "0                              1.0                         0.0   \n",
       "1                              0.0                         0.0   \n",
       "2                              1.0                         0.0   \n",
       "3                              0.0                         0.0   \n",
       "4                              1.0                         0.0   \n",
       "...                            ...                         ...   \n",
       "1465                           0.0                         0.0   \n",
       "1466                           1.0                         0.0   \n",
       "1467                           1.0                         0.0   \n",
       "1468                           0.0                         0.0   \n",
       "1469                           1.0                         0.0   \n",
       "\n",
       "      Department_Research & Development  Department_Sales  \\\n",
       "0                                   0.0               1.0   \n",
       "1                                   1.0               0.0   \n",
       "2                                   1.0               0.0   \n",
       "3                                   1.0               0.0   \n",
       "4                                   1.0               0.0   \n",
       "...                                 ...               ...   \n",
       "1465                                1.0               0.0   \n",
       "1466                                1.0               0.0   \n",
       "1467                                1.0               0.0   \n",
       "1468                                0.0               1.0   \n",
       "1469                                1.0               0.0   \n",
       "\n",
       "      Education_Associate Degree  Education_Bachelorâ€™s Degree  \\\n",
       "0                            1.0                          0.0   \n",
       "1                            0.0                          0.0   \n",
       "2                            1.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            0.0                          0.0   \n",
       "...                          ...                          ...   \n",
       "1465                         1.0                          0.0   \n",
       "1466                         0.0                          0.0   \n",
       "1467                         0.0                          1.0   \n",
       "1468                         0.0                          1.0   \n",
       "1469                         0.0                          1.0   \n",
       "\n",
       "      Education_Doctorate  Education_High School  ...  PercentSalaryHike  \\\n",
       "0                     0.0                    0.0  ...                 11   \n",
       "1                     0.0                    1.0  ...                 23   \n",
       "2                     0.0                    0.0  ...                 15   \n",
       "3                     0.0                    0.0  ...                 11   \n",
       "4                     0.0                    1.0  ...                 12   \n",
       "...                   ...                    ...  ...                ...   \n",
       "1465                  0.0                    0.0  ...                 17   \n",
       "1466                  0.0                    1.0  ...                 15   \n",
       "1467                  0.0                    0.0  ...                 20   \n",
       "1468                  0.0                    0.0  ...                 14   \n",
       "1469                  0.0                    0.0  ...                 12   \n",
       "\n",
       "      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "0                    0                  8                      0   \n",
       "1                    1                 10                      3   \n",
       "2                    0                  7                      3   \n",
       "3                    0                  8                      3   \n",
       "4                    1                  6                      3   \n",
       "...                ...                ...                    ...   \n",
       "1465                 1                 17                      3   \n",
       "1466                 1                  9                      5   \n",
       "1467                 1                  6                      0   \n",
       "1468                 0                 17                      3   \n",
       "1469                 0                  6                      3   \n",
       "\n",
       "      YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0                  6                   4                        0   \n",
       "1                 10                   7                        1   \n",
       "2                  0                   0                        0   \n",
       "3                  8                   7                        3   \n",
       "4                  2                   2                        2   \n",
       "...              ...                 ...                      ...   \n",
       "1465               5                   2                        0   \n",
       "1466               7                   7                        1   \n",
       "1467               6                   2                        0   \n",
       "1468               9                   6                        0   \n",
       "1469               4                   3                        1   \n",
       "\n",
       "      YearsWithCurrManager  annual_salary  economic_impact  \n",
       "0                        5          71916        14670.864  \n",
       "1                        7          61560        12558.240  \n",
       "2                        0          25080         4037.880  \n",
       "3                        0          34908         6876.876  \n",
       "4                        2          41616         8198.352  \n",
       "...                    ...            ...              ...  \n",
       "1465                     3          30852         6077.844  \n",
       "1466                     7         119892        25177.320  \n",
       "1467                     3          73704        15035.616  \n",
       "1468                     8          64680        13194.720  \n",
       "1469                     2          52848        10780.992  \n",
       "\n",
       "[1470 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\TrendingPC\\Desktop\\PROYECTOS\\HHRR-IBM_ATTRITION\\HR-Employee-ML.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8dfe02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Attrition')\n",
    "y = df['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb34f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1029, 78), (441, 78), (1029,), (441,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separation of the dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42,stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0aefa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fraudulent Count for Full data :   237\n",
      " Fraudulent Count for Train data :  166\n",
      " Fraudulent Count for Test data :    71\n"
     ]
    }
   ],
   "source": [
    "# Check dataset composition\n",
    "\n",
    "print(\" Fraudulent Count for Full data :  \",np.sum(y))\n",
    "print(\" Fraudulent Count for Train data : \",np.sum(y_train))\n",
    "print(\" Fraudulent Count for Test data :   \",np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9578de4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_test & y_test\n"
     ]
    }
   ],
   "source": [
    "# Save the testing set for evaluation\n",
    "X_test_saved = X_test.copy()\n",
    "y_test_saved = y_test.copy()\n",
    "print(\"Saved X_test & y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffa5f0",
   "metadata": {},
   "source": [
    "## 1.- Transformaciones de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc54450",
   "metadata": {},
   "source": [
    "## Dataset Original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117e3bb",
   "metadata": {},
   "source": [
    "### Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0a1eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 863, 1: 166})\n",
      "Resampled dataset shape Counter({0: 863, 1: 863})\n"
     ]
    }
   ],
   "source": [
    "# Import of specific libraries\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initial situation\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "# Calculate OverSampling model\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8dec3",
   "metadata": {},
   "source": [
    "### Adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311ade95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 863, 1: 166})\n",
      "Resampled dataset shape Counter({0: 863, 1: 800})\n"
     ]
    }
   ],
   "source": [
    "# Import of specific libraries\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Initial situation\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "# Calculate OverSampling model\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_adasyn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8b36a",
   "metadata": {},
   "source": [
    "## Power Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79146467",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db15189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt= preprocessing.PowerTransformer(method='yeo-johnson', copy=True)  # creates an instance of the PowerTransformer class.\n",
    "pt.fit(X_train)\n",
    "\n",
    "X_train_pt = pt.transform(X_train)\n",
    "X_test_pt = pt.transform(X_test)\n",
    "\n",
    "y_train_pt = y_train\n",
    "y_test_pt = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694755c0",
   "metadata": {},
   "source": [
    "### Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dcccda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 863, 1: 166})\n",
      "Resampled dataset shape Counter({0: 863, 1: 863})\n"
     ]
    }
   ],
   "source": [
    "# Import of specific libraries\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initial situation\n",
    "print('Original dataset shape %s' % Counter(y_train_pt))\n",
    "\n",
    "# Calculate OverSampling model\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote_pt, y_train_smote_pt = smote.fit_resample(X_train_pt, y_train_pt)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote_pt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e095c0c",
   "metadata": {},
   "source": [
    "### Adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f5e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 863, 1: 166})\n",
      "Resampled dataset shape Counter({0: 863, 1: 839})\n"
     ]
    }
   ],
   "source": [
    "# Import of specific libraries\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Initial situation\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "# Calculate OverSampling model\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_adasyn_pt, y_train_adasyn_pt = adasyn.fit_resample(X_train_pt, y_train_pt)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_adasyn_pt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280320d",
   "metadata": {},
   "source": [
    "### Load Model: Libraries and Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ead7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD OF MODELS.\n",
    "# perfom cross validation on the X_train & y_train \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize StratifiedKFold cross-validator\n",
    "# perform cross validation\n",
    "skf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "#  Shuffle is False because we need a constant best model when we use GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "965be673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c226418",
   "metadata": {},
   "source": [
    "### Create dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c51cb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original distribution\n",
    "OR_origin = ['OR origin',X_train, y_train, X_test, y_test]\n",
    "OR_smote =['OR smote',X_train_smote, y_train_smote, X_test, y_test]\n",
    "OR_adasyn = ['OR adasyn', X_train_adasyn, y_train_adasyn, X_test, y_test]\n",
    "\n",
    "# Power Transformation\n",
    "PT_origin = ['PT origin',X_train_pt, y_train_pt, X_test_pt, y_test_pt]\n",
    "PT_smote = ['PT smote',X_train_smote_pt, y_train_smote_pt, X_test_pt, y_test_pt ]\n",
    "PT_adasyn = ['PT adasyn', X_train_adasyn_pt, y_train_adasyn_pt, X_test_pt, y_test_pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728ab7a",
   "metadata": {},
   "source": [
    "### Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "222be2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['regression_logistic', 'adaboost', 'xgboost', 'catboost', 'decision_tree', 'random_forest', 'mlp', 'knn']\n",
    "parameters = [\n",
    "    [0.1, 0.5, 1, 1.5, 2, 2.5, 3],      # For 'regression_logistic'\n",
    "    [5, 7, 9],                          # For 'adaboost'\n",
    "    [0.001, 0.01, 0.1, 0.5, 1, 3],      # For 'xgboost'\n",
    "    [100, 200, 300, 400, 500, 600],      # For 'catboost'\n",
    "    [1, 2, 3, 4, 5],                    # For 'decision_tree'\n",
    "    [100, 200, 400, 600, 800, 1000, 1200],  # For 'random_forest'\n",
    "    [(50,), (100,), (120,), (150,)],     # For 'mlp'\n",
    "    [3, 5, 7]  #knn\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0357cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions =[OR_origin, OR_smote, OR_adasyn, PT_origin, PT_smote, PT_adasyn]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14696d14-fa4c-4db3-a7ae-38cc4ef97c6b",
   "metadata": {},
   "source": [
    "distributions =[OR_origin, OR_smote, OR_adasyn, PT_origin, PT_smote, PT_adasyn]\n",
    "complete_model = zip(model_list, parameters)\n",
    "complete_model_list = list(complete_model )\n",
    "complete_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f20351c3-6186-49e4-a733-26e77b4bb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b857fb0c-9f45-4ad3-8d3a-8628047d43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, fbeta_score, confusion_matrix\n",
    ")\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def gen_models_with_three_params(complete_model_list, distributions, save_directory_complete_model=None):\n",
    "    \"\"\"\n",
    "    Trains models with three levels of parameters and saves the results.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    complete_model_list : list\n",
    "        List of tuples where each tuple contains:\n",
    "        - model_name (str): Name of the model.\n",
    "        - param_grid (dict): Dictionary with lists of values for three hyperparameters.\n",
    "\n",
    "    distributions : list\n",
    "        List of datasets where each entry contains:\n",
    "        - Name of the distribution.\n",
    "        - X_train, y_train, X_val, y_val.\n",
    "\n",
    "    save_directory_complete_model : str, optional\n",
    "        Directory to save the results. Defaults to a folder named 'total' in the current working directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Combined results of all models for further processing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create directory if not provided\n",
    "    if save_directory_complete_model is None:\n",
    "        save_directory_complete_model = os.path.join(os.getcwd(), 'total')\n",
    "    os.makedirs(save_directory_complete_model, exist_ok=True)\n",
    "\n",
    "    all_results = []  # To store results from all models\n",
    "\n",
    "    # Iterate over models\n",
    "    for model_name, param_grid in complete_model_list:\n",
    "        resultados_totales = []\n",
    "\n",
    "        # Generate combinations of parameters\n",
    "        keys, values = zip(*param_grid.items())\n",
    "        param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "        # Iterate over distributions\n",
    "        for distribution in distributions:\n",
    "            try:\n",
    "                # Unpack distribution\n",
    "                name = distribution[0]\n",
    "                X_train, y_train, X_val, y_val = distribution[1:]\n",
    "\n",
    "                # Skip invalid data\n",
    "                if X_train is None or y_train is None or X_val is None or y_val is None:\n",
    "                    print(f\"    Skipping due to missing data in {name}\")\n",
    "                    continue\n",
    "\n",
    "                # Iterate over parameter combinations\n",
    "                for params in param_combinations:\n",
    "                    # Initialize model with parameters\n",
    "                    if model_name == 'regression_logistic':\n",
    "                        model_instance = LogisticRegression(\n",
    "                            C=params['C'],\n",
    "                            penalty=params['penalty'],\n",
    "                            max_iter=params['max_iter']\n",
    "                        )\n",
    "                        parameter_description = f\"C={params['C']}, penalty={params['penalty']}, max_iter={params['max_iter']}\"\n",
    "                    elif model_name == 'random_forest':\n",
    "                        model_instance = RandomForestClassifier(\n",
    "                            n_estimators=params['n_estimators'],\n",
    "                            criterion=params['criterion'],\n",
    "                            max_depth=params['max_depth']\n",
    "                        )\n",
    "                        parameter_description = f\"n_estimators={params['n_estimators']}, criterion={params['criterion']}, max_depth={params['max_depth']}\"\n",
    "                    elif model_name == 'xgboost':\n",
    "                        model_instance = XGBClassifier(\n",
    "                            learning_rate=params['learning_rate'],\n",
    "                            booster=params['booster'],\n",
    "                            n_estimators=params['n_estimators']\n",
    "                        )\n",
    "                        parameter_description = f\"learning_rate={params['learning_rate']}, booster={params['booster']}, n_estimators={params['n_estimators']}\"\n",
    "                    elif model_name == 'decision_tree':\n",
    "                        model_instance = DecisionTreeClassifier(\n",
    "                            criterion=params['criterion'],\n",
    "                            max_depth=params['max_depth'],\n",
    "                        )\n",
    "                        parameter_description = f\"criterion={params['criterion']}, max_depth={params['max_depth']}\"\n",
    "                    elif model_name == 'adaboost':\n",
    "                        model_instance = AdaBoostClassifier(\n",
    "                            n_estimators=params['n_estimators'],\n",
    "                            learning_rate=params['learning_rate'],\n",
    "                            algorithm=params['algorithm']\n",
    "                        )\n",
    "                        parameter_description = f\"n_estimators={params['n_estimators']}, learning_rate={params['learning_rate']}, algorithm={params['algorithm']}\"\n",
    "                    elif model_name == 'catboost':\n",
    "                        model_instance = CatBoostClassifier(\n",
    "                            learning_rate=params['learning_rate'],\n",
    "                            depth=params['depth'],\n",
    "                            iterations=params['iterations'],\n",
    "                            verbose=0  # Suppress verbose output\n",
    "                        )\n",
    "                        parameter_description = f\"learning_rate={params['learning_rate']}, depth={params['depth']}, iterations={params['iterations']}\"\n",
    "                    else:\n",
    "                        print(f\"    Invalid model name: {model_name}\")\n",
    "                        continue\n",
    "\n",
    "                    # Train model\n",
    "                    model_instance.fit(X_train, y_train)\n",
    "\n",
    "                    # Get predictions\n",
    "                    y_pred = model_instance.predict(X_val)\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    roc_auc = roc_auc_score(y_val, y_pred)\n",
    "                    accuracy = accuracy_score(y_val, y_pred)\n",
    "                    precision = precision_score(y_val, y_pred)\n",
    "                    recall = recall_score(y_val, y_pred)\n",
    "                    f1 = f1_score(y_val, y_pred)\n",
    "                    f2 = fbeta_score(y_val, y_pred, beta=2)\n",
    "                    confusion = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "                    # Save results in DataFrame\n",
    "                    results_df = pd.DataFrame({\n",
    "                        'Model': [model_name],\n",
    "                        'Description': [name],\n",
    "                        'Parameter_Description': [parameter_description],\n",
    "                        'ROC-AUC': [roc_auc],\n",
    "                        'Accuracy': [accuracy],\n",
    "                        'Precision': [precision],\n",
    "                        'Recall': [recall],\n",
    "                        'F1 Score': [f1],\n",
    "                        'F2 Score': [f2],\n",
    "                        'Confusion Matrix': [confusion.tolist()],  # Convert to list for compatibility\n",
    "                    })\n",
    "\n",
    "                    resultados_totales.append(results_df)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing distribution {name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Save results for this model\n",
    "        if resultados_totales:\n",
    "            df_resultados_final = pd.concat(resultados_totales, ignore_index=True)\n",
    "            save_path = os.path.join(save_directory_complete_model, f\"{model_name}_total.csv\")\n",
    "            df_resultados_final.to_csv(save_path, index=False)\n",
    "            display(HTML(f\"<h2 style='text-align: center;font-size:60px;'> Modelo: {model_name}</h2>\"))\n",
    "            display(df_resultados_final)\n",
    "            print(f\"\\n\\n\\nResults for {model_name} saved to {save_path}\")\n",
    "            all_results.append(df_resultados_final)\n",
    "        else:\n",
    "            print(f\"No results generated for {model_name}\")\n",
    "\n",
    "    # Combine all results into a single DataFrame\n",
    "    if all_results:\n",
    "        combined_results = pd.concat(all_results, ignore_index=True)\n",
    "        return combined_results\n",
    "    else:\n",
    "        print(\"No results generated for any model\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67c981c7-2107-4612-bef3-97ad39adcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model_list = [\n",
    "    ('regression_logistic', {'C': [2, 2.5, 3 ], 'penalty': ['none'], 'max_iter': [ 125,150, 200]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "755a4c4a-cb34-4798-838a-9bd60defeca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style='text-align: center;font-size:60px;'> Modelo: regression_logistic</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>[[252, 118], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>[[252, 118], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>[[252, 118], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.594062</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>[[252, 118], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>[[248, 122], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.428894</td>\n",
       "      <td>[[249, 121], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.594062</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>[[252, 118], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>[[248, 122], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.428894</td>\n",
       "      <td>[[249, 121], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.594062</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>[[252, 118], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>[[248, 122], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.428894</td>\n",
       "      <td>[[249, 121], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Description              Parameter_Description  \\\n",
       "0   regression_logistic   OR origin    C=2, penalty=none, max_iter=125   \n",
       "1   regression_logistic   OR origin    C=2, penalty=none, max_iter=150   \n",
       "2   regression_logistic   OR origin    C=2, penalty=none, max_iter=200   \n",
       "3   regression_logistic   OR origin  C=2.5, penalty=none, max_iter=125   \n",
       "4   regression_logistic   OR origin  C=2.5, penalty=none, max_iter=150   \n",
       "5   regression_logistic   OR origin  C=2.5, penalty=none, max_iter=200   \n",
       "6   regression_logistic   OR origin    C=3, penalty=none, max_iter=125   \n",
       "7   regression_logistic   OR origin    C=3, penalty=none, max_iter=150   \n",
       "8   regression_logistic   OR origin    C=3, penalty=none, max_iter=200   \n",
       "9   regression_logistic    OR smote    C=2, penalty=none, max_iter=125   \n",
       "10  regression_logistic    OR smote    C=2, penalty=none, max_iter=150   \n",
       "11  regression_logistic    OR smote    C=2, penalty=none, max_iter=200   \n",
       "12  regression_logistic    OR smote  C=2.5, penalty=none, max_iter=125   \n",
       "13  regression_logistic    OR smote  C=2.5, penalty=none, max_iter=150   \n",
       "14  regression_logistic    OR smote  C=2.5, penalty=none, max_iter=200   \n",
       "15  regression_logistic    OR smote    C=3, penalty=none, max_iter=125   \n",
       "16  regression_logistic    OR smote    C=3, penalty=none, max_iter=150   \n",
       "17  regression_logistic    OR smote    C=3, penalty=none, max_iter=200   \n",
       "18  regression_logistic   OR adasyn    C=2, penalty=none, max_iter=125   \n",
       "19  regression_logistic   OR adasyn    C=2, penalty=none, max_iter=150   \n",
       "20  regression_logistic   OR adasyn    C=2, penalty=none, max_iter=200   \n",
       "21  regression_logistic   OR adasyn  C=2.5, penalty=none, max_iter=125   \n",
       "22  regression_logistic   OR adasyn  C=2.5, penalty=none, max_iter=150   \n",
       "23  regression_logistic   OR adasyn  C=2.5, penalty=none, max_iter=200   \n",
       "24  regression_logistic   OR adasyn    C=3, penalty=none, max_iter=125   \n",
       "25  regression_logistic   OR adasyn    C=3, penalty=none, max_iter=150   \n",
       "26  regression_logistic   OR adasyn    C=3, penalty=none, max_iter=200   \n",
       "27  regression_logistic   PT origin    C=2, penalty=none, max_iter=125   \n",
       "28  regression_logistic   PT origin    C=2, penalty=none, max_iter=150   \n",
       "29  regression_logistic   PT origin    C=2, penalty=none, max_iter=200   \n",
       "30  regression_logistic   PT origin  C=2.5, penalty=none, max_iter=125   \n",
       "31  regression_logistic   PT origin  C=2.5, penalty=none, max_iter=150   \n",
       "32  regression_logistic   PT origin  C=2.5, penalty=none, max_iter=200   \n",
       "33  regression_logistic   PT origin    C=3, penalty=none, max_iter=125   \n",
       "34  regression_logistic   PT origin    C=3, penalty=none, max_iter=150   \n",
       "35  regression_logistic   PT origin    C=3, penalty=none, max_iter=200   \n",
       "36  regression_logistic    PT smote    C=2, penalty=none, max_iter=125   \n",
       "37  regression_logistic    PT smote    C=2, penalty=none, max_iter=150   \n",
       "38  regression_logistic    PT smote    C=2, penalty=none, max_iter=200   \n",
       "39  regression_logistic    PT smote  C=2.5, penalty=none, max_iter=125   \n",
       "40  regression_logistic    PT smote  C=2.5, penalty=none, max_iter=150   \n",
       "41  regression_logistic    PT smote  C=2.5, penalty=none, max_iter=200   \n",
       "42  regression_logistic    PT smote    C=3, penalty=none, max_iter=125   \n",
       "43  regression_logistic    PT smote    C=3, penalty=none, max_iter=150   \n",
       "44  regression_logistic    PT smote    C=3, penalty=none, max_iter=200   \n",
       "45  regression_logistic   PT adasyn    C=2, penalty=none, max_iter=125   \n",
       "46  regression_logistic   PT adasyn    C=2, penalty=none, max_iter=150   \n",
       "47  regression_logistic   PT adasyn    C=2, penalty=none, max_iter=200   \n",
       "48  regression_logistic   PT adasyn  C=2.5, penalty=none, max_iter=125   \n",
       "49  regression_logistic   PT adasyn  C=2.5, penalty=none, max_iter=150   \n",
       "50  regression_logistic   PT adasyn  C=2.5, penalty=none, max_iter=200   \n",
       "51  regression_logistic   PT adasyn    C=3, penalty=none, max_iter=125   \n",
       "52  regression_logistic   PT adasyn    C=3, penalty=none, max_iter=150   \n",
       "53  regression_logistic   PT adasyn    C=3, penalty=none, max_iter=200   \n",
       "\n",
       "     ROC-AUC  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "1   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "2   0.514085  0.843537   1.000000  0.028169  0.054795  0.034965   \n",
       "3   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "4   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "5   0.514085  0.843537   1.000000  0.028169  0.054795  0.034965   \n",
       "6   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "7   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "8   0.514085  0.843537   1.000000  0.028169  0.054795  0.034965   \n",
       "9   0.615188  0.659864   0.248408  0.549296  0.342105  0.442177   \n",
       "10  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "11  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "12  0.615188  0.659864   0.248408  0.549296  0.342105  0.442177   \n",
       "13  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "14  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "15  0.615188  0.659864   0.248408  0.549296  0.342105  0.442177   \n",
       "16  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "17  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "18  0.594062  0.653061   0.233766  0.507042  0.320000  0.410959   \n",
       "19  0.602741  0.648526   0.237500  0.535211  0.329004  0.427928   \n",
       "20  0.604092  0.650794   0.238994  0.535211  0.330435  0.428894   \n",
       "21  0.594062  0.653061   0.233766  0.507042  0.320000  0.410959   \n",
       "22  0.602741  0.648526   0.237500  0.535211  0.329004  0.427928   \n",
       "23  0.604092  0.650794   0.238994  0.535211  0.330435  0.428894   \n",
       "24  0.594062  0.653061   0.233766  0.507042  0.320000  0.410959   \n",
       "25  0.602741  0.648526   0.237500  0.535211  0.329004  0.427928   \n",
       "26  0.604092  0.650794   0.238994  0.535211  0.330435  0.428894   \n",
       "27  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "28  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "29  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "30  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "31  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "32  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "33  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "34  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "35  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "36  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "37  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "38  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "39  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "40  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "41  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "42  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "43  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "44  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "45  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "46  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "47  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "48  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "49  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "50  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "51  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "52  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "53  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "\n",
       "          Confusion Matrix  \n",
       "0      [[369, 1], [70, 1]]  \n",
       "1      [[369, 1], [70, 1]]  \n",
       "2      [[370, 0], [69, 2]]  \n",
       "3      [[369, 1], [70, 1]]  \n",
       "4      [[369, 1], [70, 1]]  \n",
       "5      [[370, 0], [69, 2]]  \n",
       "6      [[369, 1], [70, 1]]  \n",
       "7      [[369, 1], [70, 1]]  \n",
       "8      [[370, 0], [69, 2]]  \n",
       "9   [[252, 118], [32, 39]]  \n",
       "10  [[245, 125], [32, 39]]  \n",
       "11  [[245, 125], [32, 39]]  \n",
       "12  [[252, 118], [32, 39]]  \n",
       "13  [[245, 125], [32, 39]]  \n",
       "14  [[245, 125], [32, 39]]  \n",
       "15  [[252, 118], [32, 39]]  \n",
       "16  [[245, 125], [32, 39]]  \n",
       "17  [[245, 125], [32, 39]]  \n",
       "18  [[252, 118], [35, 36]]  \n",
       "19  [[248, 122], [33, 38]]  \n",
       "20  [[249, 121], [33, 38]]  \n",
       "21  [[252, 118], [35, 36]]  \n",
       "22  [[248, 122], [33, 38]]  \n",
       "23  [[249, 121], [33, 38]]  \n",
       "24  [[252, 118], [35, 36]]  \n",
       "25  [[248, 122], [33, 38]]  \n",
       "26  [[249, 121], [33, 38]]  \n",
       "27   [[355, 15], [39, 32]]  \n",
       "28   [[355, 15], [39, 32]]  \n",
       "29   [[355, 15], [39, 32]]  \n",
       "30   [[355, 15], [39, 32]]  \n",
       "31   [[355, 15], [39, 32]]  \n",
       "32   [[355, 15], [39, 32]]  \n",
       "33   [[355, 15], [39, 32]]  \n",
       "34   [[355, 15], [39, 32]]  \n",
       "35   [[355, 15], [39, 32]]  \n",
       "36   [[308, 62], [26, 45]]  \n",
       "37   [[308, 62], [26, 45]]  \n",
       "38   [[308, 62], [26, 45]]  \n",
       "39   [[308, 62], [26, 45]]  \n",
       "40   [[308, 62], [26, 45]]  \n",
       "41   [[308, 62], [26, 45]]  \n",
       "42   [[308, 62], [26, 45]]  \n",
       "43   [[308, 62], [26, 45]]  \n",
       "44   [[308, 62], [26, 45]]  \n",
       "45   [[307, 63], [24, 47]]  \n",
       "46   [[307, 63], [24, 47]]  \n",
       "47   [[307, 63], [24, 47]]  \n",
       "48   [[307, 63], [24, 47]]  \n",
       "49   [[307, 63], [24, 47]]  \n",
       "50   [[307, 63], [24, 47]]  \n",
       "51   [[307, 63], [24, 47]]  \n",
       "52   [[307, 63], [24, 47]]  \n",
       "53   [[307, 63], [24, 47]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Results for regression_logistic saved to C:\\Users\\TrendingPC\\Desktop\\PROYECTOS\\HHRR-IBM_ATTRITION\\total\\regression_logistic_total.csv\n"
     ]
    }
   ],
   "source": [
    "reg_log_opt = gen_models_with_three_params(complete_model_list, distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8daa6e4e-f89f-4da8-a1c2-7d1ab771a548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.745851</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.596447</td>\n",
       "      <td>[[307, 63], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.733118</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>[[308, 62], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>[[355, 15], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>[[252, 118], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>[[252, 118], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>[[252, 118], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.605729</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.331915</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>[[245, 125], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.428894</td>\n",
       "      <td>[[249, 121], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.428894</td>\n",
       "      <td>[[249, 121], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.604092</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.428894</td>\n",
       "      <td>[[249, 121], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>[[248, 122], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>[[248, 122], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.602741</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>[[248, 122], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.594062</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>[[252, 118], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.594062</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>[[252, 118], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.594062</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>[[252, 118], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=200</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=200</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=200</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=150</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2.5, penalty=none, max_iter=125</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=150</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=125</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=3, penalty=none, max_iter=150</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regression_logistic</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>C=2, penalty=none, max_iter=125</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>[[369, 1], [70, 1]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Description              Parameter_Description  \\\n",
       "53  regression_logistic   PT adasyn    C=3, penalty=none, max_iter=200   \n",
       "52  regression_logistic   PT adasyn    C=3, penalty=none, max_iter=150   \n",
       "51  regression_logistic   PT adasyn    C=3, penalty=none, max_iter=125   \n",
       "50  regression_logistic   PT adasyn  C=2.5, penalty=none, max_iter=200   \n",
       "49  regression_logistic   PT adasyn  C=2.5, penalty=none, max_iter=150   \n",
       "48  regression_logistic   PT adasyn  C=2.5, penalty=none, max_iter=125   \n",
       "47  regression_logistic   PT adasyn    C=2, penalty=none, max_iter=200   \n",
       "46  regression_logistic   PT adasyn    C=2, penalty=none, max_iter=150   \n",
       "45  regression_logistic   PT adasyn    C=2, penalty=none, max_iter=125   \n",
       "40  regression_logistic    PT smote  C=2.5, penalty=none, max_iter=150   \n",
       "36  regression_logistic    PT smote    C=2, penalty=none, max_iter=125   \n",
       "37  regression_logistic    PT smote    C=2, penalty=none, max_iter=150   \n",
       "38  regression_logistic    PT smote    C=2, penalty=none, max_iter=200   \n",
       "39  regression_logistic    PT smote  C=2.5, penalty=none, max_iter=125   \n",
       "41  regression_logistic    PT smote  C=2.5, penalty=none, max_iter=200   \n",
       "42  regression_logistic    PT smote    C=3, penalty=none, max_iter=125   \n",
       "43  regression_logistic    PT smote    C=3, penalty=none, max_iter=150   \n",
       "44  regression_logistic    PT smote    C=3, penalty=none, max_iter=200   \n",
       "28  regression_logistic   PT origin    C=2, penalty=none, max_iter=150   \n",
       "35  regression_logistic   PT origin    C=3, penalty=none, max_iter=200   \n",
       "34  regression_logistic   PT origin    C=3, penalty=none, max_iter=150   \n",
       "33  regression_logistic   PT origin    C=3, penalty=none, max_iter=125   \n",
       "32  regression_logistic   PT origin  C=2.5, penalty=none, max_iter=200   \n",
       "31  regression_logistic   PT origin  C=2.5, penalty=none, max_iter=150   \n",
       "30  regression_logistic   PT origin  C=2.5, penalty=none, max_iter=125   \n",
       "29  regression_logistic   PT origin    C=2, penalty=none, max_iter=200   \n",
       "27  regression_logistic   PT origin    C=2, penalty=none, max_iter=125   \n",
       "9   regression_logistic    OR smote    C=2, penalty=none, max_iter=125   \n",
       "12  regression_logistic    OR smote  C=2.5, penalty=none, max_iter=125   \n",
       "15  regression_logistic    OR smote    C=3, penalty=none, max_iter=125   \n",
       "14  regression_logistic    OR smote  C=2.5, penalty=none, max_iter=200   \n",
       "17  regression_logistic    OR smote    C=3, penalty=none, max_iter=200   \n",
       "10  regression_logistic    OR smote    C=2, penalty=none, max_iter=150   \n",
       "11  regression_logistic    OR smote    C=2, penalty=none, max_iter=200   \n",
       "13  regression_logistic    OR smote  C=2.5, penalty=none, max_iter=150   \n",
       "16  regression_logistic    OR smote    C=3, penalty=none, max_iter=150   \n",
       "20  regression_logistic   OR adasyn    C=2, penalty=none, max_iter=200   \n",
       "26  regression_logistic   OR adasyn    C=3, penalty=none, max_iter=200   \n",
       "23  regression_logistic   OR adasyn  C=2.5, penalty=none, max_iter=200   \n",
       "19  regression_logistic   OR adasyn    C=2, penalty=none, max_iter=150   \n",
       "22  regression_logistic   OR adasyn  C=2.5, penalty=none, max_iter=150   \n",
       "25  regression_logistic   OR adasyn    C=3, penalty=none, max_iter=150   \n",
       "18  regression_logistic   OR adasyn    C=2, penalty=none, max_iter=125   \n",
       "21  regression_logistic   OR adasyn  C=2.5, penalty=none, max_iter=125   \n",
       "24  regression_logistic   OR adasyn    C=3, penalty=none, max_iter=125   \n",
       "8   regression_logistic   OR origin    C=3, penalty=none, max_iter=200   \n",
       "2   regression_logistic   OR origin    C=2, penalty=none, max_iter=200   \n",
       "5   regression_logistic   OR origin  C=2.5, penalty=none, max_iter=200   \n",
       "4   regression_logistic   OR origin  C=2.5, penalty=none, max_iter=150   \n",
       "3   regression_logistic   OR origin  C=2.5, penalty=none, max_iter=125   \n",
       "1   regression_logistic   OR origin    C=2, penalty=none, max_iter=150   \n",
       "6   regression_logistic   OR origin    C=3, penalty=none, max_iter=125   \n",
       "7   regression_logistic   OR origin    C=3, penalty=none, max_iter=150   \n",
       "0   regression_logistic   OR origin    C=2, penalty=none, max_iter=125   \n",
       "\n",
       "     ROC-AUC  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "53  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "52  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "51  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "50  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "49  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "48  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "47  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "46  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "45  0.745851  0.802721   0.427273  0.661972  0.519337  0.596447   \n",
       "40  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "36  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "37  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "38  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "39  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "41  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "42  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "43  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "44  0.733118  0.800454   0.420561  0.633803  0.505618  0.575448   \n",
       "28  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "35  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "34  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "33  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "32  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "31  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "30  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "29  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "27  0.705082  0.877551   0.680851  0.450704  0.542373  0.483384   \n",
       "9   0.615188  0.659864   0.248408  0.549296  0.342105  0.442177   \n",
       "12  0.615188  0.659864   0.248408  0.549296  0.342105  0.442177   \n",
       "15  0.615188  0.659864   0.248408  0.549296  0.342105  0.442177   \n",
       "14  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "17  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "10  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "11  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "13  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "16  0.605729  0.643991   0.237805  0.549296  0.331915  0.435268   \n",
       "20  0.604092  0.650794   0.238994  0.535211  0.330435  0.428894   \n",
       "26  0.604092  0.650794   0.238994  0.535211  0.330435  0.428894   \n",
       "23  0.604092  0.650794   0.238994  0.535211  0.330435  0.428894   \n",
       "19  0.602741  0.648526   0.237500  0.535211  0.329004  0.427928   \n",
       "22  0.602741  0.648526   0.237500  0.535211  0.329004  0.427928   \n",
       "25  0.602741  0.648526   0.237500  0.535211  0.329004  0.427928   \n",
       "18  0.594062  0.653061   0.233766  0.507042  0.320000  0.410959   \n",
       "21  0.594062  0.653061   0.233766  0.507042  0.320000  0.410959   \n",
       "24  0.594062  0.653061   0.233766  0.507042  0.320000  0.410959   \n",
       "8   0.514085  0.843537   1.000000  0.028169  0.054795  0.034965   \n",
       "2   0.514085  0.843537   1.000000  0.028169  0.054795  0.034965   \n",
       "5   0.514085  0.843537   1.000000  0.028169  0.054795  0.034965   \n",
       "4   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "3   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "1   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "6   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "7   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "0   0.505691  0.839002   0.500000  0.014085  0.027397  0.017483   \n",
       "\n",
       "          Confusion Matrix  \n",
       "53   [[307, 63], [24, 47]]  \n",
       "52   [[307, 63], [24, 47]]  \n",
       "51   [[307, 63], [24, 47]]  \n",
       "50   [[307, 63], [24, 47]]  \n",
       "49   [[307, 63], [24, 47]]  \n",
       "48   [[307, 63], [24, 47]]  \n",
       "47   [[307, 63], [24, 47]]  \n",
       "46   [[307, 63], [24, 47]]  \n",
       "45   [[307, 63], [24, 47]]  \n",
       "40   [[308, 62], [26, 45]]  \n",
       "36   [[308, 62], [26, 45]]  \n",
       "37   [[308, 62], [26, 45]]  \n",
       "38   [[308, 62], [26, 45]]  \n",
       "39   [[308, 62], [26, 45]]  \n",
       "41   [[308, 62], [26, 45]]  \n",
       "42   [[308, 62], [26, 45]]  \n",
       "43   [[308, 62], [26, 45]]  \n",
       "44   [[308, 62], [26, 45]]  \n",
       "28   [[355, 15], [39, 32]]  \n",
       "35   [[355, 15], [39, 32]]  \n",
       "34   [[355, 15], [39, 32]]  \n",
       "33   [[355, 15], [39, 32]]  \n",
       "32   [[355, 15], [39, 32]]  \n",
       "31   [[355, 15], [39, 32]]  \n",
       "30   [[355, 15], [39, 32]]  \n",
       "29   [[355, 15], [39, 32]]  \n",
       "27   [[355, 15], [39, 32]]  \n",
       "9   [[252, 118], [32, 39]]  \n",
       "12  [[252, 118], [32, 39]]  \n",
       "15  [[252, 118], [32, 39]]  \n",
       "14  [[245, 125], [32, 39]]  \n",
       "17  [[245, 125], [32, 39]]  \n",
       "10  [[245, 125], [32, 39]]  \n",
       "11  [[245, 125], [32, 39]]  \n",
       "13  [[245, 125], [32, 39]]  \n",
       "16  [[245, 125], [32, 39]]  \n",
       "20  [[249, 121], [33, 38]]  \n",
       "26  [[249, 121], [33, 38]]  \n",
       "23  [[249, 121], [33, 38]]  \n",
       "19  [[248, 122], [33, 38]]  \n",
       "22  [[248, 122], [33, 38]]  \n",
       "25  [[248, 122], [33, 38]]  \n",
       "18  [[252, 118], [35, 36]]  \n",
       "21  [[252, 118], [35, 36]]  \n",
       "24  [[252, 118], [35, 36]]  \n",
       "8      [[370, 0], [69, 2]]  \n",
       "2      [[370, 0], [69, 2]]  \n",
       "5      [[370, 0], [69, 2]]  \n",
       "4      [[369, 1], [70, 1]]  \n",
       "3      [[369, 1], [70, 1]]  \n",
       "1      [[369, 1], [70, 1]]  \n",
       "6      [[369, 1], [70, 1]]  \n",
       "7      [[369, 1], [70, 1]]  \n",
       "0      [[369, 1], [70, 1]]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_log_opt = reg_log_opt.sort_values(by='ROC-AUC', ascending=False)\n",
    "reg_log_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d53ef6f9-57dd-426c-8c29-c904c65eed5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                regression_logistic\n",
       "Description                                    PT adasyn\n",
       "Parameter_Description    C=3, penalty=none, max_iter=200\n",
       "ROC-AUC                                         0.745851\n",
       "Accuracy                                        0.802721\n",
       "Precision                                       0.427273\n",
       "Recall                                          0.661972\n",
       "F1 Score                                        0.519337\n",
       "F2 Score                                        0.596447\n",
       "Confusion Matrix                   [[307, 63], [24, 47]]\n",
       "Name: 53, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_log_best = reg_log_opt.iloc[0]\n",
    "reg_log_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac811f9-a59e-47b4-af5e-c176dda702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model_list = [('decision_tree', {'criterion': ['gini'], 'max_depth': [3, 5], 'max_features': [5, 7,9]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac8d8f6f-1195-4fcd-b1cb-cd2f4114e8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style='text-align: center;font-size:60px;'> Modelo: decision_tree</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.591054</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>[[354, 16], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.592406</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>[[355, 15], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.592406</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>[[355, 15], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.565093</td>\n",
       "      <td>0.804989</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>[[340, 30], [56, 15]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.560754</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.214724</td>\n",
       "      <td>[[342, 28], [57, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.560754</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.214724</td>\n",
       "      <td>[[342, 28], [57, 14]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.627903</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>[[350, 20], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.627903</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>[[350, 20], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.627903</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>[[350, 20], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.613038</td>\n",
       "      <td>0.818594</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.326409</td>\n",
       "      <td>[[339, 31], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.613038</td>\n",
       "      <td>0.818594</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.326409</td>\n",
       "      <td>[[339, 31], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.611686</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.325444</td>\n",
       "      <td>[[338, 32], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.627903</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>[[350, 20], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.627903</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>[[350, 20], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.627903</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>[[350, 20], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.603864</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.335766</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>[[327, 43], [48, 23]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.603864</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.335766</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>[[327, 43], [48, 23]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.605215</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.329513</td>\n",
       "      <td>[[328, 42], [48, 23]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.591054</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>[[354, 16], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.591054</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>[[354, 16], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.591054</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>[[354, 16], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.565093</td>\n",
       "      <td>0.804989</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>[[340, 30], [56, 15]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.566445</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.228659</td>\n",
       "      <td>[[341, 29], [56, 15]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.573487</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.243161</td>\n",
       "      <td>[[341, 29], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.674781</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.439883</td>\n",
       "      <td>[[343, 27], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.674781</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.439883</td>\n",
       "      <td>[[343, 27], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.674781</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.439883</td>\n",
       "      <td>[[343, 27], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.678055</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>[[335, 35], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.678055</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>[[335, 35], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.678055</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>[[335, 35], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.706585</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>[[304, 66], [29, 42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.706585</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>[[304, 66], [29, 42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>criterion=gini, max_depth=3</td>\n",
       "      <td>0.706585</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>[[304, 66], [29, 42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.616673</td>\n",
       "      <td>0.748299</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>[[300, 70], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.616673</td>\n",
       "      <td>0.748299</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>[[300, 70], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>criterion=gini, max_depth=5</td>\n",
       "      <td>0.616673</td>\n",
       "      <td>0.748299</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>[[300, 70], [41, 30]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Description        Parameter_Description   ROC-AUC  \\\n",
       "0   decision_tree   OR origin  criterion=gini, max_depth=3  0.591054   \n",
       "1   decision_tree   OR origin  criterion=gini, max_depth=3  0.592406   \n",
       "2   decision_tree   OR origin  criterion=gini, max_depth=3  0.592406   \n",
       "3   decision_tree   OR origin  criterion=gini, max_depth=5  0.565093   \n",
       "4   decision_tree   OR origin  criterion=gini, max_depth=5  0.560754   \n",
       "5   decision_tree   OR origin  criterion=gini, max_depth=5  0.560754   \n",
       "6   decision_tree    OR smote  criterion=gini, max_depth=3  0.627903   \n",
       "7   decision_tree    OR smote  criterion=gini, max_depth=3  0.627903   \n",
       "8   decision_tree    OR smote  criterion=gini, max_depth=3  0.627903   \n",
       "9   decision_tree    OR smote  criterion=gini, max_depth=5  0.613038   \n",
       "10  decision_tree    OR smote  criterion=gini, max_depth=5  0.613038   \n",
       "11  decision_tree    OR smote  criterion=gini, max_depth=5  0.611686   \n",
       "12  decision_tree   OR adasyn  criterion=gini, max_depth=3  0.627903   \n",
       "13  decision_tree   OR adasyn  criterion=gini, max_depth=3  0.627903   \n",
       "14  decision_tree   OR adasyn  criterion=gini, max_depth=3  0.627903   \n",
       "15  decision_tree   OR adasyn  criterion=gini, max_depth=5  0.603864   \n",
       "16  decision_tree   OR adasyn  criterion=gini, max_depth=5  0.603864   \n",
       "17  decision_tree   OR adasyn  criterion=gini, max_depth=5  0.605215   \n",
       "18  decision_tree   PT origin  criterion=gini, max_depth=3  0.591054   \n",
       "19  decision_tree   PT origin  criterion=gini, max_depth=3  0.591054   \n",
       "20  decision_tree   PT origin  criterion=gini, max_depth=3  0.591054   \n",
       "21  decision_tree   PT origin  criterion=gini, max_depth=5  0.565093   \n",
       "22  decision_tree   PT origin  criterion=gini, max_depth=5  0.566445   \n",
       "23  decision_tree   PT origin  criterion=gini, max_depth=5  0.573487   \n",
       "24  decision_tree    PT smote  criterion=gini, max_depth=3  0.674781   \n",
       "25  decision_tree    PT smote  criterion=gini, max_depth=3  0.674781   \n",
       "26  decision_tree    PT smote  criterion=gini, max_depth=3  0.674781   \n",
       "27  decision_tree    PT smote  criterion=gini, max_depth=5  0.678055   \n",
       "28  decision_tree    PT smote  criterion=gini, max_depth=5  0.678055   \n",
       "29  decision_tree    PT smote  criterion=gini, max_depth=5  0.678055   \n",
       "30  decision_tree   PT adasyn  criterion=gini, max_depth=3  0.706585   \n",
       "31  decision_tree   PT adasyn  criterion=gini, max_depth=3  0.706585   \n",
       "32  decision_tree   PT adasyn  criterion=gini, max_depth=3  0.706585   \n",
       "33  decision_tree   PT adasyn  criterion=gini, max_depth=5  0.616673   \n",
       "34  decision_tree   PT adasyn  criterion=gini, max_depth=5  0.616673   \n",
       "35  decision_tree   PT adasyn  criterion=gini, max_depth=5  0.616673   \n",
       "\n",
       "    Accuracy  Precision    Recall  F1 Score  F2 Score       Confusion Matrix  \n",
       "0   0.839002   0.500000  0.225352  0.310680  0.253165  [[354, 16], [55, 16]]  \n",
       "1   0.841270   0.516129  0.225352  0.313725  0.253968  [[355, 15], [55, 16]]  \n",
       "2   0.841270   0.516129  0.225352  0.313725  0.253968  [[355, 15], [55, 16]]  \n",
       "3   0.804989   0.333333  0.211268  0.258621  0.227964  [[340, 30], [56, 15]]  \n",
       "4   0.807256   0.333333  0.197183  0.247788  0.214724  [[342, 28], [57, 14]]  \n",
       "5   0.807256   0.333333  0.197183  0.247788  0.214724  [[342, 28], [57, 14]]  \n",
       "6   0.843537   0.523810  0.309859  0.389381  0.337423  [[350, 20], [49, 22]]  \n",
       "7   0.843537   0.523810  0.309859  0.389381  0.337423  [[350, 20], [49, 22]]  \n",
       "8   0.843537   0.523810  0.309859  0.389381  0.337423  [[350, 20], [49, 22]]  \n",
       "9   0.818594   0.415094  0.309859  0.354839  0.326409  [[339, 31], [49, 22]]  \n",
       "10  0.818594   0.415094  0.309859  0.354839  0.326409  [[339, 31], [49, 22]]  \n",
       "11  0.816327   0.407407  0.309859  0.352000  0.325444  [[338, 32], [49, 22]]  \n",
       "12  0.843537   0.523810  0.309859  0.389381  0.337423  [[350, 20], [49, 22]]  \n",
       "13  0.843537   0.523810  0.309859  0.389381  0.337423  [[350, 20], [49, 22]]  \n",
       "14  0.843537   0.523810  0.309859  0.389381  0.337423  [[350, 20], [49, 22]]  \n",
       "15  0.793651   0.348485  0.323944  0.335766  0.328571  [[327, 43], [48, 23]]  \n",
       "16  0.793651   0.348485  0.323944  0.335766  0.328571  [[327, 43], [48, 23]]  \n",
       "17  0.795918   0.353846  0.323944  0.338235  0.329513  [[328, 42], [48, 23]]  \n",
       "18  0.839002   0.500000  0.225352  0.310680  0.253165  [[354, 16], [55, 16]]  \n",
       "19  0.839002   0.500000  0.225352  0.310680  0.253165  [[354, 16], [55, 16]]  \n",
       "20  0.839002   0.500000  0.225352  0.310680  0.253165  [[354, 16], [55, 16]]  \n",
       "21  0.804989   0.333333  0.211268  0.258621  0.227964  [[340, 30], [56, 15]]  \n",
       "22  0.807256   0.340909  0.211268  0.260870  0.228659  [[341, 29], [56, 15]]  \n",
       "23  0.809524   0.355556  0.225352  0.275862  0.243161  [[341, 29], [55, 16]]  \n",
       "24  0.845805   0.526316  0.422535  0.468750  0.439883  [[343, 27], [41, 30]]  \n",
       "25  0.845805   0.526316  0.422535  0.468750  0.439883  [[343, 27], [41, 30]]  \n",
       "26  0.845805   0.526316  0.422535  0.468750  0.439883  [[343, 27], [41, 30]]  \n",
       "27  0.832200   0.477612  0.450704  0.463768  0.455840  [[335, 35], [39, 32]]  \n",
       "28  0.832200   0.477612  0.450704  0.463768  0.455840  [[335, 35], [39, 32]]  \n",
       "29  0.832200   0.477612  0.450704  0.463768  0.455840  [[335, 35], [39, 32]]  \n",
       "30  0.784580   0.388889  0.591549  0.469274  0.535714  [[304, 66], [29, 42]]  \n",
       "31  0.784580   0.388889  0.591549  0.469274  0.535714  [[304, 66], [29, 42]]  \n",
       "32  0.784580   0.388889  0.591549  0.469274  0.535714  [[304, 66], [29, 42]]  \n",
       "33  0.748299   0.300000  0.422535  0.350877  0.390625  [[300, 70], [41, 30]]  \n",
       "34  0.748299   0.300000  0.422535  0.350877  0.390625  [[300, 70], [41, 30]]  \n",
       "35  0.748299   0.300000  0.422535  0.350877  0.390625  [[300, 70], [41, 30]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Results for decision_tree saved to C:\\Users\\TrendingPC\\Desktop\\PROYECTOS\\HHRR-IBM_ATTRITION\\total\\decision_tree_total.csv\n"
     ]
    }
   ],
   "source": [
    "dec_tree_opt = gen_models_with_three_params(complete_model_list, distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eff63b62-b613-4d1a-b021-14061ed67919",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_opt = dec_tree_opt.sort_values(by='ROC-AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdcf3d6e-393c-4536-a251-813201e7c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_best = dec_tree_opt.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd6827c4-8223-444f-b6ad-4d6d1d8af341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                  decision_tree\n",
       "Description                                PT adasyn\n",
       "Parameter_Description    criterion=gini, max_depth=3\n",
       "ROC-AUC                                     0.706585\n",
       "Accuracy                                     0.78458\n",
       "Precision                                   0.388889\n",
       "Recall                                      0.591549\n",
       "F1 Score                                    0.469274\n",
       "F2 Score                                    0.535714\n",
       "Confusion Matrix               [[304, 66], [29, 42]]\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3398ddb6-20b6-4d0e-930d-63aa09fbf488",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model_list = [('random_forest', {'n_estimators':[200, 250],'criterion':['entropy'], 'max_depth': [3, 5]}) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "833866bc-78b6-4efb-92e7-6cde1fb2d58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style='text-align: center;font-size:60px;'> Modelo: random_forest</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.508679</td>\n",
       "      <td>0.834467</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>[[366, 4], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.531443</td>\n",
       "      <td>0.834467</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.100671</td>\n",
       "      <td>[[362, 8], [65, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.511667</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>[[363, 7], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>[[362, 8], [66, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.660697</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.412979</td>\n",
       "      <td>[[343, 27], [43, 28]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.653083</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.442478</td>\n",
       "      <td>0.383436</td>\n",
       "      <td>[[353, 17], [46, 25]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.646898</td>\n",
       "      <td>0.827664</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.393586</td>\n",
       "      <td>[[338, 32], [44, 27]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.633308</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.341615</td>\n",
       "      <td>[[354, 16], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.641987</td>\n",
       "      <td>0.848073</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>[[350, 20], [47, 24]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.610544</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.286624</td>\n",
       "      <td>[[358, 12], [53, 18]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.626551</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.336391</td>\n",
       "      <td>[[349, 21], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.621926</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.314465</td>\n",
       "      <td>[[356, 14], [51, 20]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.511382</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>[[368, 2], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.517358</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>[[362, 8], [67, 4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.514370</td>\n",
       "      <td>0.834467</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.051370</td>\n",
       "      <td>[[365, 5], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>[[362, 8], [66, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.683251</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>[[318, 52], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.674781</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.439883</td>\n",
       "      <td>[[343, 27], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.709783</td>\n",
       "      <td>0.818594</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.525606</td>\n",
       "      <td>[[322, 48], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.691854</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.475504</td>\n",
       "      <td>[[340, 30], [38, 33]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.685668</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.463576</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[[325, 45], [36, 35]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.649600</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.395894</td>\n",
       "      <td>[[340, 30], [44, 27]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.702741</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>[[322, 48], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.645546</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.412214</td>\n",
       "      <td>0.392442</td>\n",
       "      <td>[[337, 33], [44, 27]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Description  \\\n",
       "0   random_forest   OR origin   \n",
       "1   random_forest   OR origin   \n",
       "2   random_forest   OR origin   \n",
       "3   random_forest   OR origin   \n",
       "4   random_forest    OR smote   \n",
       "5   random_forest    OR smote   \n",
       "6   random_forest    OR smote   \n",
       "7   random_forest    OR smote   \n",
       "8   random_forest   OR adasyn   \n",
       "9   random_forest   OR adasyn   \n",
       "10  random_forest   OR adasyn   \n",
       "11  random_forest   OR adasyn   \n",
       "12  random_forest   PT origin   \n",
       "13  random_forest   PT origin   \n",
       "14  random_forest   PT origin   \n",
       "15  random_forest   PT origin   \n",
       "16  random_forest    PT smote   \n",
       "17  random_forest    PT smote   \n",
       "18  random_forest    PT smote   \n",
       "19  random_forest    PT smote   \n",
       "20  random_forest   PT adasyn   \n",
       "21  random_forest   PT adasyn   \n",
       "22  random_forest   PT adasyn   \n",
       "23  random_forest   PT adasyn   \n",
       "\n",
       "                               Parameter_Description   ROC-AUC  Accuracy  \\\n",
       "0   n_estimators=200, criterion=entropy, max_depth=3  0.508679  0.834467   \n",
       "1   n_estimators=200, criterion=entropy, max_depth=5  0.531443  0.834467   \n",
       "2   n_estimators=250, criterion=entropy, max_depth=3  0.511667  0.829932   \n",
       "3   n_estimators=250, criterion=entropy, max_depth=5  0.524400  0.832200   \n",
       "4   n_estimators=200, criterion=entropy, max_depth=3  0.660697  0.841270   \n",
       "5   n_estimators=200, criterion=entropy, max_depth=5  0.653083  0.857143   \n",
       "6   n_estimators=250, criterion=entropy, max_depth=3  0.646898  0.827664   \n",
       "7   n_estimators=250, criterion=entropy, max_depth=5  0.633308  0.852608   \n",
       "8   n_estimators=200, criterion=entropy, max_depth=3  0.641987  0.848073   \n",
       "9   n_estimators=200, criterion=entropy, max_depth=5  0.610544  0.852608   \n",
       "10  n_estimators=250, criterion=entropy, max_depth=3  0.626551  0.841270   \n",
       "11  n_estimators=250, criterion=entropy, max_depth=5  0.621926  0.852608   \n",
       "12  n_estimators=200, criterion=entropy, max_depth=3  0.511382  0.839002   \n",
       "13  n_estimators=200, criterion=entropy, max_depth=5  0.517358  0.829932   \n",
       "14  n_estimators=250, criterion=entropy, max_depth=3  0.514370  0.834467   \n",
       "15  n_estimators=250, criterion=entropy, max_depth=5  0.524400  0.832200   \n",
       "16  n_estimators=200, criterion=entropy, max_depth=3  0.683251  0.802721   \n",
       "17  n_estimators=200, criterion=entropy, max_depth=5  0.674781  0.845805   \n",
       "18  n_estimators=250, criterion=entropy, max_depth=3  0.709783  0.818594   \n",
       "19  n_estimators=250, criterion=entropy, max_depth=5  0.691854  0.845805   \n",
       "20  n_estimators=200, criterion=entropy, max_depth=3  0.685668  0.816327   \n",
       "21  n_estimators=200, criterion=entropy, max_depth=5  0.649600  0.832200   \n",
       "22  n_estimators=250, criterion=entropy, max_depth=3  0.702741  0.816327   \n",
       "23  n_estimators=250, criterion=entropy, max_depth=5  0.645546  0.825397   \n",
       "\n",
       "    Precision    Recall  F1 Score  F2 Score       Confusion Matrix  \n",
       "0    0.333333  0.028169  0.051948  0.034483    [[366, 4], [69, 2]]  \n",
       "1    0.428571  0.084507  0.141176  0.100671    [[362, 8], [65, 6]]  \n",
       "2    0.300000  0.042254  0.074074  0.051020    [[363, 7], [68, 3]]  \n",
       "3    0.384615  0.070423  0.119048  0.084175    [[362, 8], [66, 5]]  \n",
       "4    0.509091  0.394366  0.444444  0.412979  [[343, 27], [43, 28]]  \n",
       "5    0.595238  0.352113  0.442478  0.383436  [[353, 17], [46, 25]]  \n",
       "6    0.457627  0.380282  0.415385  0.393586  [[338, 32], [44, 27]]  \n",
       "7    0.578947  0.309859  0.403670  0.341615  [[354, 16], [49, 22]]  \n",
       "8    0.545455  0.338028  0.417391  0.365854  [[350, 20], [47, 24]]  \n",
       "9    0.600000  0.253521  0.356436  0.286624  [[358, 12], [53, 18]]  \n",
       "10   0.511628  0.309859  0.385965  0.336391  [[349, 21], [49, 22]]  \n",
       "11   0.588235  0.281690  0.380952  0.314465  [[356, 14], [51, 20]]  \n",
       "12   0.500000  0.028169  0.053333  0.034722    [[368, 2], [69, 2]]  \n",
       "13   0.333333  0.056338  0.096386  0.067568    [[362, 8], [67, 4]]  \n",
       "14   0.375000  0.042254  0.075949  0.051370    [[365, 5], [68, 3]]  \n",
       "15   0.384615  0.070423  0.119048  0.084175    [[362, 8], [66, 5]]  \n",
       "16   0.409091  0.507042  0.452830  0.483871  [[318, 52], [35, 36]]  \n",
       "17   0.526316  0.422535  0.468750  0.439883  [[343, 27], [41, 30]]  \n",
       "18   0.448276  0.549296  0.493671  0.525606  [[322, 48], [32, 39]]  \n",
       "19   0.523810  0.464789  0.492537  0.475504  [[340, 30], [38, 33]]  \n",
       "20   0.437500  0.492958  0.463576  0.480769  [[325, 45], [36, 35]]  \n",
       "21   0.473684  0.380282  0.421875  0.395894  [[340, 30], [44, 27]]  \n",
       "22   0.441860  0.535211  0.484076  0.513514  [[322, 48], [33, 38]]  \n",
       "23   0.450000  0.380282  0.412214  0.392442  [[337, 33], [44, 27]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Results for random_forest saved to C:\\Users\\TrendingPC\\Desktop\\PROYECTOS\\HHRR-IBM_ATTRITION\\total\\random_forest_total.csv\n"
     ]
    }
   ],
   "source": [
    "random_forest_opt = gen_models_with_three_params(complete_model_list, distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26b8f0f5-e7ab-442b-a7d4-ac921a897deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.709783</td>\n",
       "      <td>0.818594</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.525606</td>\n",
       "      <td>[[322, 48], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.702741</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>[[322, 48], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.691854</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.475504</td>\n",
       "      <td>[[340, 30], [38, 33]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.685668</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.463576</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[[325, 45], [36, 35]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.683251</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>[[318, 52], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.674781</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.439883</td>\n",
       "      <td>[[343, 27], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.660697</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.412979</td>\n",
       "      <td>[[343, 27], [43, 28]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.653083</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.442478</td>\n",
       "      <td>0.383436</td>\n",
       "      <td>[[353, 17], [46, 25]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.649600</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.395894</td>\n",
       "      <td>[[340, 30], [44, 27]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.646898</td>\n",
       "      <td>0.827664</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.393586</td>\n",
       "      <td>[[338, 32], [44, 27]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.645546</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.412214</td>\n",
       "      <td>0.392442</td>\n",
       "      <td>[[337, 33], [44, 27]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.641987</td>\n",
       "      <td>0.848073</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>[[350, 20], [47, 24]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.633308</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.341615</td>\n",
       "      <td>[[354, 16], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.626551</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.336391</td>\n",
       "      <td>[[349, 21], [49, 22]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.621926</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.314465</td>\n",
       "      <td>[[356, 14], [51, 20]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.610544</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.286624</td>\n",
       "      <td>[[358, 12], [53, 18]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.531443</td>\n",
       "      <td>0.834467</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.100671</td>\n",
       "      <td>[[362, 8], [65, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>[[362, 8], [66, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>[[362, 8], [66, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=5</td>\n",
       "      <td>0.517358</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>[[362, 8], [67, 4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.514370</td>\n",
       "      <td>0.834467</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.051370</td>\n",
       "      <td>[[365, 5], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=250, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.511667</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>[[363, 7], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.511382</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>[[368, 2], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=200, criterion=entropy, max_depth=3</td>\n",
       "      <td>0.508679</td>\n",
       "      <td>0.834467</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>[[366, 4], [69, 2]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Description  \\\n",
       "18  random_forest    PT smote   \n",
       "22  random_forest   PT adasyn   \n",
       "19  random_forest    PT smote   \n",
       "20  random_forest   PT adasyn   \n",
       "16  random_forest    PT smote   \n",
       "17  random_forest    PT smote   \n",
       "4   random_forest    OR smote   \n",
       "5   random_forest    OR smote   \n",
       "21  random_forest   PT adasyn   \n",
       "6   random_forest    OR smote   \n",
       "23  random_forest   PT adasyn   \n",
       "8   random_forest   OR adasyn   \n",
       "7   random_forest    OR smote   \n",
       "10  random_forest   OR adasyn   \n",
       "11  random_forest   OR adasyn   \n",
       "9   random_forest   OR adasyn   \n",
       "1   random_forest   OR origin   \n",
       "15  random_forest   PT origin   \n",
       "3   random_forest   OR origin   \n",
       "13  random_forest   PT origin   \n",
       "14  random_forest   PT origin   \n",
       "2   random_forest   OR origin   \n",
       "12  random_forest   PT origin   \n",
       "0   random_forest   OR origin   \n",
       "\n",
       "                               Parameter_Description   ROC-AUC  Accuracy  \\\n",
       "18  n_estimators=250, criterion=entropy, max_depth=3  0.709783  0.818594   \n",
       "22  n_estimators=250, criterion=entropy, max_depth=3  0.702741  0.816327   \n",
       "19  n_estimators=250, criterion=entropy, max_depth=5  0.691854  0.845805   \n",
       "20  n_estimators=200, criterion=entropy, max_depth=3  0.685668  0.816327   \n",
       "16  n_estimators=200, criterion=entropy, max_depth=3  0.683251  0.802721   \n",
       "17  n_estimators=200, criterion=entropy, max_depth=5  0.674781  0.845805   \n",
       "4   n_estimators=200, criterion=entropy, max_depth=3  0.660697  0.841270   \n",
       "5   n_estimators=200, criterion=entropy, max_depth=5  0.653083  0.857143   \n",
       "21  n_estimators=200, criterion=entropy, max_depth=5  0.649600  0.832200   \n",
       "6   n_estimators=250, criterion=entropy, max_depth=3  0.646898  0.827664   \n",
       "23  n_estimators=250, criterion=entropy, max_depth=5  0.645546  0.825397   \n",
       "8   n_estimators=200, criterion=entropy, max_depth=3  0.641987  0.848073   \n",
       "7   n_estimators=250, criterion=entropy, max_depth=5  0.633308  0.852608   \n",
       "10  n_estimators=250, criterion=entropy, max_depth=3  0.626551  0.841270   \n",
       "11  n_estimators=250, criterion=entropy, max_depth=5  0.621926  0.852608   \n",
       "9   n_estimators=200, criterion=entropy, max_depth=5  0.610544  0.852608   \n",
       "1   n_estimators=200, criterion=entropy, max_depth=5  0.531443  0.834467   \n",
       "15  n_estimators=250, criterion=entropy, max_depth=5  0.524400  0.832200   \n",
       "3   n_estimators=250, criterion=entropy, max_depth=5  0.524400  0.832200   \n",
       "13  n_estimators=200, criterion=entropy, max_depth=5  0.517358  0.829932   \n",
       "14  n_estimators=250, criterion=entropy, max_depth=3  0.514370  0.834467   \n",
       "2   n_estimators=250, criterion=entropy, max_depth=3  0.511667  0.829932   \n",
       "12  n_estimators=200, criterion=entropy, max_depth=3  0.511382  0.839002   \n",
       "0   n_estimators=200, criterion=entropy, max_depth=3  0.508679  0.834467   \n",
       "\n",
       "    Precision    Recall  F1 Score  F2 Score       Confusion Matrix  \n",
       "18   0.448276  0.549296  0.493671  0.525606  [[322, 48], [32, 39]]  \n",
       "22   0.441860  0.535211  0.484076  0.513514  [[322, 48], [33, 38]]  \n",
       "19   0.523810  0.464789  0.492537  0.475504  [[340, 30], [38, 33]]  \n",
       "20   0.437500  0.492958  0.463576  0.480769  [[325, 45], [36, 35]]  \n",
       "16   0.409091  0.507042  0.452830  0.483871  [[318, 52], [35, 36]]  \n",
       "17   0.526316  0.422535  0.468750  0.439883  [[343, 27], [41, 30]]  \n",
       "4    0.509091  0.394366  0.444444  0.412979  [[343, 27], [43, 28]]  \n",
       "5    0.595238  0.352113  0.442478  0.383436  [[353, 17], [46, 25]]  \n",
       "21   0.473684  0.380282  0.421875  0.395894  [[340, 30], [44, 27]]  \n",
       "6    0.457627  0.380282  0.415385  0.393586  [[338, 32], [44, 27]]  \n",
       "23   0.450000  0.380282  0.412214  0.392442  [[337, 33], [44, 27]]  \n",
       "8    0.545455  0.338028  0.417391  0.365854  [[350, 20], [47, 24]]  \n",
       "7    0.578947  0.309859  0.403670  0.341615  [[354, 16], [49, 22]]  \n",
       "10   0.511628  0.309859  0.385965  0.336391  [[349, 21], [49, 22]]  \n",
       "11   0.588235  0.281690  0.380952  0.314465  [[356, 14], [51, 20]]  \n",
       "9    0.600000  0.253521  0.356436  0.286624  [[358, 12], [53, 18]]  \n",
       "1    0.428571  0.084507  0.141176  0.100671    [[362, 8], [65, 6]]  \n",
       "15   0.384615  0.070423  0.119048  0.084175    [[362, 8], [66, 5]]  \n",
       "3    0.384615  0.070423  0.119048  0.084175    [[362, 8], [66, 5]]  \n",
       "13   0.333333  0.056338  0.096386  0.067568    [[362, 8], [67, 4]]  \n",
       "14   0.375000  0.042254  0.075949  0.051370    [[365, 5], [68, 3]]  \n",
       "2    0.300000  0.042254  0.074074  0.051020    [[363, 7], [68, 3]]  \n",
       "12   0.500000  0.028169  0.053333  0.034722    [[368, 2], [69, 2]]  \n",
       "0    0.333333  0.028169  0.051948  0.034483    [[366, 4], [69, 2]]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_opt = random_forest_opt.sort_values(by='ROC-AUC', ascending=False)\n",
    "random_forest_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6ac23ed-daff-4858-b0bf-b41117cd6bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                                       random_forest\n",
       "Description                                                      PT smote\n",
       "Parameter_Description    n_estimators=250, criterion=entropy, max_depth=3\n",
       "ROC-AUC                                                          0.709783\n",
       "Accuracy                                                         0.818594\n",
       "Precision                                                        0.448276\n",
       "Recall                                                           0.549296\n",
       "F1 Score                                                         0.493671\n",
       "F2 Score                                                         0.525606\n",
       "Confusion Matrix                                    [[322, 48], [32, 39]]\n",
       "Name: 18, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_best = random_forest_opt.iloc[0]\n",
    "random_forest_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5028049-831f-498b-84ec-2ac8cb81b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model_list = [\n",
    "    ('xgboost', {'learning_rate': [0.001, 0.05, 0.1], 'booster': ['gblinear'], 'n_estimators': [50, 100, 200]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3019ea46-294c-4bb7-a1e5-698508731ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style='text-align: center;font-size:60px;'> Modelo: xgboost</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.635725</td>\n",
       "      <td>0.866213</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>0.334395</td>\n",
       "      <td>[[361, 9], [50, 21]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.685306</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.443425</td>\n",
       "      <td>[[356, 14], [42, 29]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.688295</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.453172</td>\n",
       "      <td>[[353, 17], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.692349</td>\n",
       "      <td>0.875283</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>[[356, 14], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.688295</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.453172</td>\n",
       "      <td>[[353, 17], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.701028</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>[[352, 18], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.720099</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>0.549738</td>\n",
       "      <td>[[314, 56], [29, 42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>0.786848</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.576441</td>\n",
       "      <td>[[301, 69], [25, 46]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.734260</td>\n",
       "      <td>0.764172</td>\n",
       "      <td>0.374046</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.485149</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>[[288, 82], [22, 49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.750190</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.424779</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.604534</td>\n",
       "      <td>[[305, 65], [23, 48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.738809</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.585242</td>\n",
       "      <td>[[307, 63], [25, 46]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.723087</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.556995</td>\n",
       "      <td>[[311, 59], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.731766</td>\n",
       "      <td>0.798186</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>0.573980</td>\n",
       "      <td>[[307, 63], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.723087</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.556995</td>\n",
       "      <td>[[311, 59], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.721736</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.494253</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>[[310, 60], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.603217</td>\n",
       "      <td>0.859410</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.260586</td>\n",
       "      <td>[[363, 7], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.706224</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>[[335, 35], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.738238</td>\n",
       "      <td>0.818594</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.577428</td>\n",
       "      <td>[[317, 53], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.723373</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>[[306, 64], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.723373</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>[[306, 64], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.728778</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.502857</td>\n",
       "      <td>0.567010</td>\n",
       "      <td>[[310, 60], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.724724</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>0.562660</td>\n",
       "      <td>[[307, 63], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.728778</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.502857</td>\n",
       "      <td>0.567010</td>\n",
       "      <td>[[310, 60], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.725790</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.559896</td>\n",
       "      <td>[[313, 57], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.519775</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>[[369, 1], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.689360</td>\n",
       "      <td>0.879819</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.447531</td>\n",
       "      <td>[[359, 11], [42, 29]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.684126</td>\n",
       "      <td>0.594104</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.393220</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>[[204, 166], [13, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.677084</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.255605</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.562130</td>\n",
       "      <td>[[204, 166], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.686544</td>\n",
       "      <td>0.607710</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.397213</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>[[211, 159], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.755101</td>\n",
       "      <td>0.780045</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.512563</td>\n",
       "      <td>0.618932</td>\n",
       "      <td>[[293, 77], [20, 51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.746136</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[[302, 68], [23, 48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.744499</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>[[306, 64], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.741797</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.415929</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.591940</td>\n",
       "      <td>[[304, 66], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.744499</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>[[306, 64], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.745565</td>\n",
       "      <td>0.811791</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.525714</td>\n",
       "      <td>0.592784</td>\n",
       "      <td>[[312, 58], [25, 46]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.700057</td>\n",
       "      <td>0.630385</td>\n",
       "      <td>0.276699</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.411552</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>[[221, 149], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.694652</td>\n",
       "      <td>0.621315</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.405694</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>[[217, 153], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.708451</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.418773</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>[[222, 148], [13, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.766483</td>\n",
       "      <td>0.780045</td>\n",
       "      <td>0.401515</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.522167</td>\n",
       "      <td>0.637019</td>\n",
       "      <td>[[291, 79], [18, 53]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.746422</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.401639</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>[[297, 73], [22, 49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.739094</td>\n",
       "      <td>0.791383</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.588972</td>\n",
       "      <td>[[302, 68], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.746422</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.401639</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>[[297, 73], [22, 49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.739094</td>\n",
       "      <td>0.791383</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.588972</td>\n",
       "      <td>[[302, 68], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.740445</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.508108</td>\n",
       "      <td>0.590452</td>\n",
       "      <td>[[303, 67], [24, 47]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Description  \\\n",
       "0   xgboost   OR origin   \n",
       "1   xgboost   OR origin   \n",
       "2   xgboost   OR origin   \n",
       "3   xgboost   OR origin   \n",
       "4   xgboost   OR origin   \n",
       "5   xgboost   OR origin   \n",
       "6   xgboost   OR origin   \n",
       "7   xgboost   OR origin   \n",
       "8   xgboost   OR origin   \n",
       "9   xgboost    OR smote   \n",
       "10  xgboost    OR smote   \n",
       "11  xgboost    OR smote   \n",
       "12  xgboost    OR smote   \n",
       "13  xgboost    OR smote   \n",
       "14  xgboost    OR smote   \n",
       "15  xgboost    OR smote   \n",
       "16  xgboost    OR smote   \n",
       "17  xgboost    OR smote   \n",
       "18  xgboost   OR adasyn   \n",
       "19  xgboost   OR adasyn   \n",
       "20  xgboost   OR adasyn   \n",
       "21  xgboost   OR adasyn   \n",
       "22  xgboost   OR adasyn   \n",
       "23  xgboost   OR adasyn   \n",
       "24  xgboost   OR adasyn   \n",
       "25  xgboost   OR adasyn   \n",
       "26  xgboost   OR adasyn   \n",
       "27  xgboost   PT origin   \n",
       "28  xgboost   PT origin   \n",
       "29  xgboost   PT origin   \n",
       "30  xgboost   PT origin   \n",
       "31  xgboost   PT origin   \n",
       "32  xgboost   PT origin   \n",
       "33  xgboost   PT origin   \n",
       "34  xgboost   PT origin   \n",
       "35  xgboost   PT origin   \n",
       "36  xgboost    PT smote   \n",
       "37  xgboost    PT smote   \n",
       "38  xgboost    PT smote   \n",
       "39  xgboost    PT smote   \n",
       "40  xgboost    PT smote   \n",
       "41  xgboost    PT smote   \n",
       "42  xgboost    PT smote   \n",
       "43  xgboost    PT smote   \n",
       "44  xgboost    PT smote   \n",
       "45  xgboost   PT adasyn   \n",
       "46  xgboost   PT adasyn   \n",
       "47  xgboost   PT adasyn   \n",
       "48  xgboost   PT adasyn   \n",
       "49  xgboost   PT adasyn   \n",
       "50  xgboost   PT adasyn   \n",
       "51  xgboost   PT adasyn   \n",
       "52  xgboost   PT adasyn   \n",
       "53  xgboost   PT adasyn   \n",
       "\n",
       "                                      Parameter_Description   ROC-AUC  \\\n",
       "0    learning_rate=0.001, booster=gblinear, n_estimators=50  0.500000   \n",
       "1   learning_rate=0.001, booster=gblinear, n_estimators=100  0.500000   \n",
       "2   learning_rate=0.001, booster=gblinear, n_estimators=200  0.500000   \n",
       "3     learning_rate=0.05, booster=gblinear, n_estimators=50  0.635725   \n",
       "4    learning_rate=0.05, booster=gblinear, n_estimators=100  0.685306   \n",
       "5    learning_rate=0.05, booster=gblinear, n_estimators=200  0.688295   \n",
       "6      learning_rate=0.1, booster=gblinear, n_estimators=50  0.692349   \n",
       "7     learning_rate=0.1, booster=gblinear, n_estimators=100  0.688295   \n",
       "8     learning_rate=0.1, booster=gblinear, n_estimators=200  0.701028   \n",
       "9    learning_rate=0.001, booster=gblinear, n_estimators=50  0.720099   \n",
       "10  learning_rate=0.001, booster=gblinear, n_estimators=100  0.730700   \n",
       "11  learning_rate=0.001, booster=gblinear, n_estimators=200  0.734260   \n",
       "12    learning_rate=0.05, booster=gblinear, n_estimators=50  0.750190   \n",
       "13   learning_rate=0.05, booster=gblinear, n_estimators=100  0.738809   \n",
       "14   learning_rate=0.05, booster=gblinear, n_estimators=200  0.723087   \n",
       "15     learning_rate=0.1, booster=gblinear, n_estimators=50  0.731766   \n",
       "16    learning_rate=0.1, booster=gblinear, n_estimators=100  0.723087   \n",
       "17    learning_rate=0.1, booster=gblinear, n_estimators=200  0.721736   \n",
       "18   learning_rate=0.001, booster=gblinear, n_estimators=50  0.603217   \n",
       "19  learning_rate=0.001, booster=gblinear, n_estimators=100  0.706224   \n",
       "20  learning_rate=0.001, booster=gblinear, n_estimators=200  0.738238   \n",
       "21    learning_rate=0.05, booster=gblinear, n_estimators=50  0.723373   \n",
       "22   learning_rate=0.05, booster=gblinear, n_estimators=100  0.723373   \n",
       "23   learning_rate=0.05, booster=gblinear, n_estimators=200  0.728778   \n",
       "24     learning_rate=0.1, booster=gblinear, n_estimators=50  0.724724   \n",
       "25    learning_rate=0.1, booster=gblinear, n_estimators=100  0.728778   \n",
       "26    learning_rate=0.1, booster=gblinear, n_estimators=200  0.725790   \n",
       "27   learning_rate=0.001, booster=gblinear, n_estimators=50  0.500000   \n",
       "28  learning_rate=0.001, booster=gblinear, n_estimators=100  0.500000   \n",
       "29  learning_rate=0.001, booster=gblinear, n_estimators=200  0.519775   \n",
       "30    learning_rate=0.05, booster=gblinear, n_estimators=50  0.689360   \n",
       "31   learning_rate=0.05, booster=gblinear, n_estimators=100  0.707785   \n",
       "32   learning_rate=0.05, booster=gblinear, n_estimators=200  0.707785   \n",
       "33     learning_rate=0.1, booster=gblinear, n_estimators=50  0.707785   \n",
       "34    learning_rate=0.1, booster=gblinear, n_estimators=100  0.707785   \n",
       "35    learning_rate=0.1, booster=gblinear, n_estimators=200  0.707785   \n",
       "36   learning_rate=0.001, booster=gblinear, n_estimators=50  0.684126   \n",
       "37  learning_rate=0.001, booster=gblinear, n_estimators=100  0.677084   \n",
       "38  learning_rate=0.001, booster=gblinear, n_estimators=200  0.686544   \n",
       "39    learning_rate=0.05, booster=gblinear, n_estimators=50  0.755101   \n",
       "40   learning_rate=0.05, booster=gblinear, n_estimators=100  0.746136   \n",
       "41   learning_rate=0.05, booster=gblinear, n_estimators=200  0.744499   \n",
       "42     learning_rate=0.1, booster=gblinear, n_estimators=50  0.741797   \n",
       "43    learning_rate=0.1, booster=gblinear, n_estimators=100  0.744499   \n",
       "44    learning_rate=0.1, booster=gblinear, n_estimators=200  0.745565   \n",
       "45   learning_rate=0.001, booster=gblinear, n_estimators=50  0.700057   \n",
       "46  learning_rate=0.001, booster=gblinear, n_estimators=100  0.694652   \n",
       "47  learning_rate=0.001, booster=gblinear, n_estimators=200  0.708451   \n",
       "48    learning_rate=0.05, booster=gblinear, n_estimators=50  0.766483   \n",
       "49   learning_rate=0.05, booster=gblinear, n_estimators=100  0.746422   \n",
       "50   learning_rate=0.05, booster=gblinear, n_estimators=200  0.739094   \n",
       "51     learning_rate=0.1, booster=gblinear, n_estimators=50  0.746422   \n",
       "52    learning_rate=0.1, booster=gblinear, n_estimators=100  0.739094   \n",
       "53    learning_rate=0.1, booster=gblinear, n_estimators=200  0.740445   \n",
       "\n",
       "    Accuracy  Precision    Recall  F1 Score  F2 Score        Confusion Matrix  \n",
       "0   0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "1   0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "2   0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "3   0.866213   0.700000  0.295775  0.415842  0.334395    [[361, 9], [50, 21]]  \n",
       "4   0.873016   0.674419  0.408451  0.508772  0.443425   [[356, 14], [42, 29]]  \n",
       "5   0.868481   0.638298  0.422535  0.508475  0.453172   [[353, 17], [41, 30]]  \n",
       "6   0.875283   0.681818  0.422535  0.521739  0.457317   [[356, 14], [41, 30]]  \n",
       "7   0.868481   0.638298  0.422535  0.508475  0.453172   [[353, 17], [41, 30]]  \n",
       "8   0.870748   0.640000  0.450704  0.528926  0.479042   [[352, 18], [39, 32]]  \n",
       "9   0.807256   0.428571  0.591549  0.497041  0.549738   [[314, 56], [29, 42]]  \n",
       "10  0.786848   0.400000  0.647887  0.494624  0.576441   [[301, 69], [25, 46]]  \n",
       "11  0.764172   0.374046  0.690141  0.485149  0.590361   [[288, 82], [22, 49]]  \n",
       "12  0.800454   0.424779  0.676056  0.521739  0.604534   [[305, 65], [23, 48]]  \n",
       "13  0.800454   0.422018  0.647887  0.511111  0.585242   [[307, 63], [25, 46]]  \n",
       "14  0.802721   0.421569  0.605634  0.497110  0.556995   [[311, 59], [28, 43]]  \n",
       "15  0.798186   0.416667  0.633803  0.502793  0.573980   [[307, 63], [26, 45]]  \n",
       "16  0.802721   0.421569  0.605634  0.497110  0.556995   [[311, 59], [28, 43]]  \n",
       "17  0.800454   0.417476  0.605634  0.494253  0.555556   [[310, 60], [28, 43]]  \n",
       "18  0.859410   0.695652  0.225352  0.340426  0.260586    [[363, 7], [55, 16]]  \n",
       "19  0.841270   0.507042  0.507042  0.507042  0.507042   [[335, 35], [35, 36]]  \n",
       "20  0.818594   0.453608  0.619718  0.523810  0.577428   [[317, 53], [27, 44]]  \n",
       "21  0.793651   0.407407  0.619718  0.491620  0.561224   [[306, 64], [27, 44]]  \n",
       "22  0.793651   0.407407  0.619718  0.491620  0.561224   [[306, 64], [27, 44]]  \n",
       "23  0.802721   0.423077  0.619718  0.502857  0.567010   [[310, 60], [27, 44]]  \n",
       "24  0.795918   0.411215  0.619718  0.494382  0.562660   [[307, 63], [27, 44]]  \n",
       "25  0.802721   0.423077  0.619718  0.502857  0.567010   [[310, 60], [27, 44]]  \n",
       "26  0.807256   0.430000  0.605634  0.502924  0.559896   [[313, 57], [28, 43]]  \n",
       "27  0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "28  0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "29  0.843537   0.750000  0.042254  0.080000  0.052083     [[369, 1], [68, 3]]  \n",
       "30  0.879819   0.725000  0.408451  0.522523  0.447531   [[359, 11], [42, 29]]  \n",
       "31  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "32  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "33  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "34  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "35  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "36  0.594104   0.258929  0.816901  0.393220  0.570866  [[204, 166], [13, 58]]  \n",
       "37  0.591837   0.255605  0.802817  0.387755  0.562130  [[204, 166], [14, 57]]  \n",
       "38  0.607710   0.263889  0.802817  0.397213  0.570000  [[211, 159], [14, 57]]  \n",
       "39  0.780045   0.398438  0.718310  0.512563  0.618932   [[293, 77], [20, 51]]  \n",
       "40  0.793651   0.413793  0.676056  0.513369  0.600000   [[302, 68], [23, 48]]  \n",
       "41  0.800454   0.423423  0.661972  0.516484  0.594937   [[306, 64], [24, 47]]  \n",
       "42  0.795918   0.415929  0.661972  0.510870  0.591940   [[304, 66], [24, 47]]  \n",
       "43  0.800454   0.423423  0.661972  0.516484  0.594937   [[306, 64], [24, 47]]  \n",
       "44  0.811791   0.442308  0.647887  0.525714  0.592784   [[312, 58], [25, 46]]  \n",
       "45  0.630385   0.276699  0.802817  0.411552  0.581633  [[221, 149], [14, 57]]  \n",
       "46  0.621315   0.271429  0.802817  0.405694  0.576923  [[217, 153], [14, 57]]  \n",
       "47  0.634921   0.281553  0.816901  0.418773  0.591837  [[222, 148], [13, 58]]  \n",
       "48  0.780045   0.401515  0.746479  0.522167  0.637019   [[291, 79], [18, 53]]  \n",
       "49  0.784580   0.401639  0.690141  0.507772  0.603448   [[297, 73], [22, 49]]  \n",
       "50  0.791383   0.408696  0.661972  0.505376  0.588972   [[302, 68], [24, 47]]  \n",
       "51  0.784580   0.401639  0.690141  0.507772  0.603448   [[297, 73], [22, 49]]  \n",
       "52  0.791383   0.408696  0.661972  0.505376  0.588972   [[302, 68], [24, 47]]  \n",
       "53  0.793651   0.412281  0.661972  0.508108  0.590452   [[303, 67], [24, 47]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Results for xgboost saved to C:\\HHRR\\01_total_models\\xgboost_total.csv\n"
     ]
    }
   ],
   "source": [
    "xgboost_opt = gen_models_with_three_params(complete_model_list, distributions, path_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dcf1a841-0811-4f72-a8ed-a4eb0a5c231f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.766483</td>\n",
       "      <td>0.780045</td>\n",
       "      <td>0.401515</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.522167</td>\n",
       "      <td>0.637019</td>\n",
       "      <td>[[291, 79], [18, 53]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.755101</td>\n",
       "      <td>0.780045</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.512563</td>\n",
       "      <td>0.618932</td>\n",
       "      <td>[[293, 77], [20, 51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.750190</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.424779</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.604534</td>\n",
       "      <td>[[305, 65], [23, 48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.746422</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.401639</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>[[297, 73], [22, 49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.746422</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.401639</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>[[297, 73], [22, 49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.746136</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[[302, 68], [23, 48]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.744499</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>[[306, 64], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.744499</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>[[306, 64], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.745565</td>\n",
       "      <td>0.811791</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.525714</td>\n",
       "      <td>0.592784</td>\n",
       "      <td>[[312, 58], [25, 46]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.741797</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.415929</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.591940</td>\n",
       "      <td>[[304, 66], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.708451</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.418773</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>[[222, 148], [13, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.740445</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.508108</td>\n",
       "      <td>0.590452</td>\n",
       "      <td>[[303, 67], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.734260</td>\n",
       "      <td>0.764172</td>\n",
       "      <td>0.374046</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.485149</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>[[288, 82], [22, 49]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.739094</td>\n",
       "      <td>0.791383</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.588972</td>\n",
       "      <td>[[302, 68], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.739094</td>\n",
       "      <td>0.791383</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.588972</td>\n",
       "      <td>[[302, 68], [24, 47]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.738809</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.585242</td>\n",
       "      <td>[[307, 63], [25, 46]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.700057</td>\n",
       "      <td>0.630385</td>\n",
       "      <td>0.276699</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.411552</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>[[221, 149], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.738238</td>\n",
       "      <td>0.818594</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.577428</td>\n",
       "      <td>[[317, 53], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.694652</td>\n",
       "      <td>0.621315</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.405694</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>[[217, 153], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>0.786848</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.576441</td>\n",
       "      <td>[[301, 69], [25, 46]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.731766</td>\n",
       "      <td>0.798186</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>0.573980</td>\n",
       "      <td>[[307, 63], [26, 45]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.684126</td>\n",
       "      <td>0.594104</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.393220</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>[[204, 166], [13, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.686544</td>\n",
       "      <td>0.607710</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.397213</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>[[211, 159], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.728778</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.502857</td>\n",
       "      <td>0.567010</td>\n",
       "      <td>[[310, 60], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.728778</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.502857</td>\n",
       "      <td>0.567010</td>\n",
       "      <td>[[310, 60], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.724724</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.411215</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>0.562660</td>\n",
       "      <td>[[307, 63], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.677084</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.255605</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.562130</td>\n",
       "      <td>[[204, 166], [14, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.723373</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>[[306, 64], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.723373</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>[[306, 64], [27, 44]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.725790</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.559896</td>\n",
       "      <td>[[313, 57], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.723087</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.556995</td>\n",
       "      <td>[[311, 59], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.723087</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.556995</td>\n",
       "      <td>[[311, 59], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.721736</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.494253</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>[[310, 60], [28, 43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR smote</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.720099</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>0.549738</td>\n",
       "      <td>[[314, 56], [29, 42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.706224</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>[[335, 35], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.707785</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>[[357, 13], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.701028</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>[[352, 18], [39, 32]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.692349</td>\n",
       "      <td>0.875283</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>[[356, 14], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.1, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.688295</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.453172</td>\n",
       "      <td>[[353, 17], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.688295</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.453172</td>\n",
       "      <td>[[353, 17], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.689360</td>\n",
       "      <td>0.879819</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.447531</td>\n",
       "      <td>[[359, 11], [42, 29]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.685306</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.443425</td>\n",
       "      <td>[[356, 14], [42, 29]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.05, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.635725</td>\n",
       "      <td>0.866213</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>0.334395</td>\n",
       "      <td>[[361, 9], [50, 21]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR adasyn</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.603217</td>\n",
       "      <td>0.859410</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.260586</td>\n",
       "      <td>[[363, 7], [55, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.519775</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>[[369, 1], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>PT origin</td>\n",
       "      <td>learning_rate=0.001, booster=gblinear, n_estimators=50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Description  \\\n",
       "48  xgboost   PT adasyn   \n",
       "39  xgboost    PT smote   \n",
       "12  xgboost    OR smote   \n",
       "51  xgboost   PT adasyn   \n",
       "49  xgboost   PT adasyn   \n",
       "40  xgboost    PT smote   \n",
       "43  xgboost    PT smote   \n",
       "41  xgboost    PT smote   \n",
       "44  xgboost    PT smote   \n",
       "42  xgboost    PT smote   \n",
       "47  xgboost   PT adasyn   \n",
       "53  xgboost   PT adasyn   \n",
       "11  xgboost    OR smote   \n",
       "52  xgboost   PT adasyn   \n",
       "50  xgboost   PT adasyn   \n",
       "13  xgboost    OR smote   \n",
       "45  xgboost   PT adasyn   \n",
       "20  xgboost   OR adasyn   \n",
       "46  xgboost   PT adasyn   \n",
       "10  xgboost    OR smote   \n",
       "15  xgboost    OR smote   \n",
       "36  xgboost    PT smote   \n",
       "38  xgboost    PT smote   \n",
       "25  xgboost   OR adasyn   \n",
       "23  xgboost   OR adasyn   \n",
       "24  xgboost   OR adasyn   \n",
       "37  xgboost    PT smote   \n",
       "21  xgboost   OR adasyn   \n",
       "22  xgboost   OR adasyn   \n",
       "26  xgboost   OR adasyn   \n",
       "14  xgboost    OR smote   \n",
       "16  xgboost    OR smote   \n",
       "17  xgboost    OR smote   \n",
       "9   xgboost    OR smote   \n",
       "19  xgboost   OR adasyn   \n",
       "32  xgboost   PT origin   \n",
       "33  xgboost   PT origin   \n",
       "34  xgboost   PT origin   \n",
       "35  xgboost   PT origin   \n",
       "31  xgboost   PT origin   \n",
       "8   xgboost   OR origin   \n",
       "6   xgboost   OR origin   \n",
       "7   xgboost   OR origin   \n",
       "5   xgboost   OR origin   \n",
       "30  xgboost   PT origin   \n",
       "4   xgboost   OR origin   \n",
       "3   xgboost   OR origin   \n",
       "18  xgboost   OR adasyn   \n",
       "29  xgboost   PT origin   \n",
       "0   xgboost   OR origin   \n",
       "28  xgboost   PT origin   \n",
       "1   xgboost   OR origin   \n",
       "2   xgboost   OR origin   \n",
       "27  xgboost   PT origin   \n",
       "\n",
       "                                      Parameter_Description   ROC-AUC  \\\n",
       "48    learning_rate=0.05, booster=gblinear, n_estimators=50  0.766483   \n",
       "39    learning_rate=0.05, booster=gblinear, n_estimators=50  0.755101   \n",
       "12    learning_rate=0.05, booster=gblinear, n_estimators=50  0.750190   \n",
       "51     learning_rate=0.1, booster=gblinear, n_estimators=50  0.746422   \n",
       "49   learning_rate=0.05, booster=gblinear, n_estimators=100  0.746422   \n",
       "40   learning_rate=0.05, booster=gblinear, n_estimators=100  0.746136   \n",
       "43    learning_rate=0.1, booster=gblinear, n_estimators=100  0.744499   \n",
       "41   learning_rate=0.05, booster=gblinear, n_estimators=200  0.744499   \n",
       "44    learning_rate=0.1, booster=gblinear, n_estimators=200  0.745565   \n",
       "42     learning_rate=0.1, booster=gblinear, n_estimators=50  0.741797   \n",
       "47  learning_rate=0.001, booster=gblinear, n_estimators=200  0.708451   \n",
       "53    learning_rate=0.1, booster=gblinear, n_estimators=200  0.740445   \n",
       "11  learning_rate=0.001, booster=gblinear, n_estimators=200  0.734260   \n",
       "52    learning_rate=0.1, booster=gblinear, n_estimators=100  0.739094   \n",
       "50   learning_rate=0.05, booster=gblinear, n_estimators=200  0.739094   \n",
       "13   learning_rate=0.05, booster=gblinear, n_estimators=100  0.738809   \n",
       "45   learning_rate=0.001, booster=gblinear, n_estimators=50  0.700057   \n",
       "20  learning_rate=0.001, booster=gblinear, n_estimators=200  0.738238   \n",
       "46  learning_rate=0.001, booster=gblinear, n_estimators=100  0.694652   \n",
       "10  learning_rate=0.001, booster=gblinear, n_estimators=100  0.730700   \n",
       "15     learning_rate=0.1, booster=gblinear, n_estimators=50  0.731766   \n",
       "36   learning_rate=0.001, booster=gblinear, n_estimators=50  0.684126   \n",
       "38  learning_rate=0.001, booster=gblinear, n_estimators=200  0.686544   \n",
       "25    learning_rate=0.1, booster=gblinear, n_estimators=100  0.728778   \n",
       "23   learning_rate=0.05, booster=gblinear, n_estimators=200  0.728778   \n",
       "24     learning_rate=0.1, booster=gblinear, n_estimators=50  0.724724   \n",
       "37  learning_rate=0.001, booster=gblinear, n_estimators=100  0.677084   \n",
       "21    learning_rate=0.05, booster=gblinear, n_estimators=50  0.723373   \n",
       "22   learning_rate=0.05, booster=gblinear, n_estimators=100  0.723373   \n",
       "26    learning_rate=0.1, booster=gblinear, n_estimators=200  0.725790   \n",
       "14   learning_rate=0.05, booster=gblinear, n_estimators=200  0.723087   \n",
       "16    learning_rate=0.1, booster=gblinear, n_estimators=100  0.723087   \n",
       "17    learning_rate=0.1, booster=gblinear, n_estimators=200  0.721736   \n",
       "9    learning_rate=0.001, booster=gblinear, n_estimators=50  0.720099   \n",
       "19  learning_rate=0.001, booster=gblinear, n_estimators=100  0.706224   \n",
       "32   learning_rate=0.05, booster=gblinear, n_estimators=200  0.707785   \n",
       "33     learning_rate=0.1, booster=gblinear, n_estimators=50  0.707785   \n",
       "34    learning_rate=0.1, booster=gblinear, n_estimators=100  0.707785   \n",
       "35    learning_rate=0.1, booster=gblinear, n_estimators=200  0.707785   \n",
       "31   learning_rate=0.05, booster=gblinear, n_estimators=100  0.707785   \n",
       "8     learning_rate=0.1, booster=gblinear, n_estimators=200  0.701028   \n",
       "6      learning_rate=0.1, booster=gblinear, n_estimators=50  0.692349   \n",
       "7     learning_rate=0.1, booster=gblinear, n_estimators=100  0.688295   \n",
       "5    learning_rate=0.05, booster=gblinear, n_estimators=200  0.688295   \n",
       "30    learning_rate=0.05, booster=gblinear, n_estimators=50  0.689360   \n",
       "4    learning_rate=0.05, booster=gblinear, n_estimators=100  0.685306   \n",
       "3     learning_rate=0.05, booster=gblinear, n_estimators=50  0.635725   \n",
       "18   learning_rate=0.001, booster=gblinear, n_estimators=50  0.603217   \n",
       "29  learning_rate=0.001, booster=gblinear, n_estimators=200  0.519775   \n",
       "0    learning_rate=0.001, booster=gblinear, n_estimators=50  0.500000   \n",
       "28  learning_rate=0.001, booster=gblinear, n_estimators=100  0.500000   \n",
       "1   learning_rate=0.001, booster=gblinear, n_estimators=100  0.500000   \n",
       "2   learning_rate=0.001, booster=gblinear, n_estimators=200  0.500000   \n",
       "27   learning_rate=0.001, booster=gblinear, n_estimators=50  0.500000   \n",
       "\n",
       "    Accuracy  Precision    Recall  F1 Score  F2 Score        Confusion Matrix  \n",
       "48  0.780045   0.401515  0.746479  0.522167  0.637019   [[291, 79], [18, 53]]  \n",
       "39  0.780045   0.398438  0.718310  0.512563  0.618932   [[293, 77], [20, 51]]  \n",
       "12  0.800454   0.424779  0.676056  0.521739  0.604534   [[305, 65], [23, 48]]  \n",
       "51  0.784580   0.401639  0.690141  0.507772  0.603448   [[297, 73], [22, 49]]  \n",
       "49  0.784580   0.401639  0.690141  0.507772  0.603448   [[297, 73], [22, 49]]  \n",
       "40  0.793651   0.413793  0.676056  0.513369  0.600000   [[302, 68], [23, 48]]  \n",
       "43  0.800454   0.423423  0.661972  0.516484  0.594937   [[306, 64], [24, 47]]  \n",
       "41  0.800454   0.423423  0.661972  0.516484  0.594937   [[306, 64], [24, 47]]  \n",
       "44  0.811791   0.442308  0.647887  0.525714  0.592784   [[312, 58], [25, 46]]  \n",
       "42  0.795918   0.415929  0.661972  0.510870  0.591940   [[304, 66], [24, 47]]  \n",
       "47  0.634921   0.281553  0.816901  0.418773  0.591837  [[222, 148], [13, 58]]  \n",
       "53  0.793651   0.412281  0.661972  0.508108  0.590452   [[303, 67], [24, 47]]  \n",
       "11  0.764172   0.374046  0.690141  0.485149  0.590361   [[288, 82], [22, 49]]  \n",
       "52  0.791383   0.408696  0.661972  0.505376  0.588972   [[302, 68], [24, 47]]  \n",
       "50  0.791383   0.408696  0.661972  0.505376  0.588972   [[302, 68], [24, 47]]  \n",
       "13  0.800454   0.422018  0.647887  0.511111  0.585242   [[307, 63], [25, 46]]  \n",
       "45  0.630385   0.276699  0.802817  0.411552  0.581633  [[221, 149], [14, 57]]  \n",
       "20  0.818594   0.453608  0.619718  0.523810  0.577428   [[317, 53], [27, 44]]  \n",
       "46  0.621315   0.271429  0.802817  0.405694  0.576923  [[217, 153], [14, 57]]  \n",
       "10  0.786848   0.400000  0.647887  0.494624  0.576441   [[301, 69], [25, 46]]  \n",
       "15  0.798186   0.416667  0.633803  0.502793  0.573980   [[307, 63], [26, 45]]  \n",
       "36  0.594104   0.258929  0.816901  0.393220  0.570866  [[204, 166], [13, 58]]  \n",
       "38  0.607710   0.263889  0.802817  0.397213  0.570000  [[211, 159], [14, 57]]  \n",
       "25  0.802721   0.423077  0.619718  0.502857  0.567010   [[310, 60], [27, 44]]  \n",
       "23  0.802721   0.423077  0.619718  0.502857  0.567010   [[310, 60], [27, 44]]  \n",
       "24  0.795918   0.411215  0.619718  0.494382  0.562660   [[307, 63], [27, 44]]  \n",
       "37  0.591837   0.255605  0.802817  0.387755  0.562130  [[204, 166], [14, 57]]  \n",
       "21  0.793651   0.407407  0.619718  0.491620  0.561224   [[306, 64], [27, 44]]  \n",
       "22  0.793651   0.407407  0.619718  0.491620  0.561224   [[306, 64], [27, 44]]  \n",
       "26  0.807256   0.430000  0.605634  0.502924  0.559896   [[313, 57], [28, 43]]  \n",
       "14  0.802721   0.421569  0.605634  0.497110  0.556995   [[311, 59], [28, 43]]  \n",
       "16  0.802721   0.421569  0.605634  0.497110  0.556995   [[311, 59], [28, 43]]  \n",
       "17  0.800454   0.417476  0.605634  0.494253  0.555556   [[310, 60], [28, 43]]  \n",
       "9   0.807256   0.428571  0.591549  0.497041  0.549738   [[314, 56], [29, 42]]  \n",
       "19  0.841270   0.507042  0.507042  0.507042  0.507042   [[335, 35], [35, 36]]  \n",
       "32  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "33  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "34  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "35  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "31  0.882086   0.711111  0.450704  0.551724  0.486322   [[357, 13], [39, 32]]  \n",
       "8   0.870748   0.640000  0.450704  0.528926  0.479042   [[352, 18], [39, 32]]  \n",
       "6   0.875283   0.681818  0.422535  0.521739  0.457317   [[356, 14], [41, 30]]  \n",
       "7   0.868481   0.638298  0.422535  0.508475  0.453172   [[353, 17], [41, 30]]  \n",
       "5   0.868481   0.638298  0.422535  0.508475  0.453172   [[353, 17], [41, 30]]  \n",
       "30  0.879819   0.725000  0.408451  0.522523  0.447531   [[359, 11], [42, 29]]  \n",
       "4   0.873016   0.674419  0.408451  0.508772  0.443425   [[356, 14], [42, 29]]  \n",
       "3   0.866213   0.700000  0.295775  0.415842  0.334395    [[361, 9], [50, 21]]  \n",
       "18  0.859410   0.695652  0.225352  0.340426  0.260586    [[363, 7], [55, 16]]  \n",
       "29  0.843537   0.750000  0.042254  0.080000  0.052083     [[369, 1], [68, 3]]  \n",
       "0   0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "28  0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "1   0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "2   0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  \n",
       "27  0.839002   0.000000  0.000000  0.000000  0.000000     [[370, 0], [71, 0]]  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_opt = xgboost_opt.sort_values(by='F2 Score', ascending=False)\n",
    "xgboost_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3533f8b8-0961-4a07-adf5-79e034114510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                                                  xgboost\n",
       "Description                                                          PT adasyn\n",
       "Parameter_Description    learning_rate=0.05, booster=gblinear, n_estimators=50\n",
       "ROC-AUC                                                               0.766483\n",
       "Accuracy                                                              0.780045\n",
       "Precision                                                             0.401515\n",
       "Recall                                                                0.746479\n",
       "F1 Score                                                              0.522167\n",
       "F2 Score                                                              0.637019\n",
       "Confusion Matrix                                         [[291, 79], [18, 53]]\n",
       "Name: 48, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_best = xgboost_opt.iloc[0]\n",
    "xgboost_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3922052-30aa-4a81-8cc5-5077f8581ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model_list = [\n",
    "    ('adaboost', {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'algorithm': ['SAMME', 'SAMME.R']})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8cd260c-b936-429a-916a-3c01abdad48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style='text-align: center;font-size:60px;'> Modelo: adaboost</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.01, algorithm=SAMME</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.01, algorithm=SAMME.R</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.1, algorithm=SAMME</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.1, algorithm=SAMME.R</td>\n",
       "      <td>0.518424</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.051903</td>\n",
       "      <td>[[368, 2], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=1, algorithm=SAMME</td>\n",
       "      <td>0.606776</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>[[350, 20], [52, 19]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=0.01, algorithm=SAMME.R</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>0.768707</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>[[300, 70], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=0.1, algorithm=SAMME</td>\n",
       "      <td>0.697335</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.472050</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>[[318, 52], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=0.1, algorithm=SAMME.R</td>\n",
       "      <td>0.682394</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.466102</td>\n",
       "      <td>[[333, 37], [38, 33]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=1, algorithm=SAMME</td>\n",
       "      <td>0.672078</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.437318</td>\n",
       "      <td>[[341, 29], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=1, algorithm=SAMME.R</td>\n",
       "      <td>0.708927</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.509915</td>\n",
       "      <td>[[337, 33], [35, 36]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Description  \\\n",
       "0    adaboost   OR origin   \n",
       "1    adaboost   OR origin   \n",
       "2    adaboost   OR origin   \n",
       "3    adaboost   OR origin   \n",
       "4    adaboost   OR origin   \n",
       "..        ...         ...   \n",
       "103  adaboost   PT adasyn   \n",
       "104  adaboost   PT adasyn   \n",
       "105  adaboost   PT adasyn   \n",
       "106  adaboost   PT adasyn   \n",
       "107  adaboost   PT adasyn   \n",
       "\n",
       "                                       Parameter_Description   ROC-AUC  \\\n",
       "0       n_estimators=50, learning_rate=0.01, algorithm=SAMME  0.500000   \n",
       "1     n_estimators=50, learning_rate=0.01, algorithm=SAMME.R  0.500000   \n",
       "2        n_estimators=50, learning_rate=0.1, algorithm=SAMME  0.514085   \n",
       "3      n_estimators=50, learning_rate=0.1, algorithm=SAMME.R  0.518424   \n",
       "4          n_estimators=50, learning_rate=1, algorithm=SAMME  0.606776   \n",
       "..                                                       ...       ...   \n",
       "103  n_estimators=200, learning_rate=0.01, algorithm=SAMME.R  0.680053   \n",
       "104     n_estimators=200, learning_rate=0.1, algorithm=SAMME  0.697335   \n",
       "105   n_estimators=200, learning_rate=0.1, algorithm=SAMME.R  0.682394   \n",
       "106       n_estimators=200, learning_rate=1, algorithm=SAMME  0.672078   \n",
       "107     n_estimators=200, learning_rate=1, algorithm=SAMME.R  0.708927   \n",
       "\n",
       "     Accuracy  Precision    Recall  F1 Score  F2 Score       Confusion Matrix  \n",
       "0    0.839002   0.000000  0.000000  0.000000  0.000000    [[370, 0], [71, 0]]  \n",
       "1    0.839002   0.000000  0.000000  0.000000  0.000000    [[370, 0], [71, 0]]  \n",
       "2    0.843537   1.000000  0.028169  0.054795  0.034965    [[370, 0], [69, 2]]  \n",
       "3    0.841270   0.600000  0.042254  0.078947  0.051903    [[368, 2], [68, 3]]  \n",
       "4    0.836735   0.487179  0.267606  0.345455  0.294118  [[350, 20], [52, 19]]  \n",
       "..        ...        ...       ...       ...       ...                    ...  \n",
       "103  0.768707   0.357798  0.549296  0.433333  0.496183  [[300, 70], [32, 39]]  \n",
       "104  0.807256   0.422222  0.535211  0.472050  0.508021  [[318, 52], [33, 38]]  \n",
       "105  0.829932   0.471429  0.464789  0.468085  0.466102  [[333, 37], [38, 33]]  \n",
       "106  0.841270   0.508475  0.422535  0.461538  0.437318  [[341, 29], [41, 30]]  \n",
       "107  0.845805   0.521739  0.507042  0.514286  0.509915  [[337, 33], [35, 36]]  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Results for adaboost saved to C:\\HHRR\\01_total_models\\adaboost_total.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.01, algorithm=SAMME</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.01, algorithm=SAMME.R</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[370, 0], [71, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.1, algorithm=SAMME</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>[[370, 0], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=0.1, algorithm=SAMME.R</td>\n",
       "      <td>0.518424</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.051903</td>\n",
       "      <td>[[368, 2], [68, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>n_estimators=50, learning_rate=1, algorithm=SAMME</td>\n",
       "      <td>0.606776</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>[[350, 20], [52, 19]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=0.01, algorithm=SAMME.R</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>0.768707</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>[[300, 70], [32, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=0.1, algorithm=SAMME</td>\n",
       "      <td>0.697335</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.472050</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>[[318, 52], [33, 38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=0.1, algorithm=SAMME.R</td>\n",
       "      <td>0.682394</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.466102</td>\n",
       "      <td>[[333, 37], [38, 33]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=1, algorithm=SAMME</td>\n",
       "      <td>0.672078</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.437318</td>\n",
       "      <td>[[341, 29], [41, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>n_estimators=200, learning_rate=1, algorithm=SAMME.R</td>\n",
       "      <td>0.708927</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.509915</td>\n",
       "      <td>[[337, 33], [35, 36]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Description  \\\n",
       "0    adaboost   OR origin   \n",
       "1    adaboost   OR origin   \n",
       "2    adaboost   OR origin   \n",
       "3    adaboost   OR origin   \n",
       "4    adaboost   OR origin   \n",
       "..        ...         ...   \n",
       "103  adaboost   PT adasyn   \n",
       "104  adaboost   PT adasyn   \n",
       "105  adaboost   PT adasyn   \n",
       "106  adaboost   PT adasyn   \n",
       "107  adaboost   PT adasyn   \n",
       "\n",
       "                                       Parameter_Description   ROC-AUC  \\\n",
       "0       n_estimators=50, learning_rate=0.01, algorithm=SAMME  0.500000   \n",
       "1     n_estimators=50, learning_rate=0.01, algorithm=SAMME.R  0.500000   \n",
       "2        n_estimators=50, learning_rate=0.1, algorithm=SAMME  0.514085   \n",
       "3      n_estimators=50, learning_rate=0.1, algorithm=SAMME.R  0.518424   \n",
       "4          n_estimators=50, learning_rate=1, algorithm=SAMME  0.606776   \n",
       "..                                                       ...       ...   \n",
       "103  n_estimators=200, learning_rate=0.01, algorithm=SAMME.R  0.680053   \n",
       "104     n_estimators=200, learning_rate=0.1, algorithm=SAMME  0.697335   \n",
       "105   n_estimators=200, learning_rate=0.1, algorithm=SAMME.R  0.682394   \n",
       "106       n_estimators=200, learning_rate=1, algorithm=SAMME  0.672078   \n",
       "107     n_estimators=200, learning_rate=1, algorithm=SAMME.R  0.708927   \n",
       "\n",
       "     Accuracy  Precision    Recall  F1 Score  F2 Score       Confusion Matrix  \n",
       "0    0.839002   0.000000  0.000000  0.000000  0.000000    [[370, 0], [71, 0]]  \n",
       "1    0.839002   0.000000  0.000000  0.000000  0.000000    [[370, 0], [71, 0]]  \n",
       "2    0.843537   1.000000  0.028169  0.054795  0.034965    [[370, 0], [69, 2]]  \n",
       "3    0.841270   0.600000  0.042254  0.078947  0.051903    [[368, 2], [68, 3]]  \n",
       "4    0.836735   0.487179  0.267606  0.345455  0.294118  [[350, 20], [52, 19]]  \n",
       "..        ...        ...       ...       ...       ...                    ...  \n",
       "103  0.768707   0.357798  0.549296  0.433333  0.496183  [[300, 70], [32, 39]]  \n",
       "104  0.807256   0.422222  0.535211  0.472050  0.508021  [[318, 52], [33, 38]]  \n",
       "105  0.829932   0.471429  0.464789  0.468085  0.466102  [[333, 37], [38, 33]]  \n",
       "106  0.841270   0.508475  0.422535  0.461538  0.437318  [[341, 29], [41, 30]]  \n",
       "107  0.845805   0.521739  0.507042  0.514286  0.509915  [[337, 33], [35, 36]]  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_opt = gen_models_with_three_params(complete_model_list, distributions, path_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb0fc378-85c1-4738-b84b-f6965efb4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_opt = adaboost_opt.sort_values(by='ROC-AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7c879a29-f086-4cfe-84de-1321ad8ad122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                                                adaboost\n",
       "Description                                                         PT adasyn\n",
       "Parameter_Description    n_estimators=100, learning_rate=1, algorithm=SAMME.R\n",
       "ROC-AUC                                                              0.715969\n",
       "Accuracy                                                             0.848073\n",
       "Precision                                                            0.528571\n",
       "Recall                                                               0.521127\n",
       "F1 Score                                                             0.524823\n",
       "F2 Score                                                             0.522599\n",
       "Confusion Matrix                                        [[337, 33], [34, 37]]\n",
       "Name: 101, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_best = adaboost_opt.iloc[0]\n",
    "adaboost_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "408de837-46c0-495c-a77c-ef29b05dec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model_list = [\n",
    "    ('catboost', {'learning_rate': [0.01, 0.1, 0.3], 'iterations': [100, 500, 1000], 'depth': [3, 6, 10]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89ef8045-7d21-451c-a720-51cabb0f53fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style='text-align: center;font-size:60px;'> Modelo: catboost</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameter_Description</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.01, depth=3, iterations=100</td>\n",
       "      <td>0.512733</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>[[369, 1], [69, 2]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.01, depth=6, iterations=100</td>\n",
       "      <td>0.535497</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>[[365, 5], [65, 6]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.01, depth=10, iterations=100</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>0.839002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.085034</td>\n",
       "      <td>[[365, 5], [66, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.01, depth=3, iterations=500</td>\n",
       "      <td>0.566654</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.181518</td>\n",
       "      <td>[[362, 8], [60, 11]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>catboost</td>\n",
       "      <td>OR origin</td>\n",
       "      <td>learning_rate=0.01, depth=6, iterations=500</td>\n",
       "      <td>0.573696</td>\n",
       "      <td>0.848073</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>[[362, 8], [59, 12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>catboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.3, depth=6, iterations=500</td>\n",
       "      <td>0.665531</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.402477</td>\n",
       "      <td>[[357, 13], [45, 26]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>catboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.3, depth=10, iterations=500</td>\n",
       "      <td>0.653864</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.367412</td>\n",
       "      <td>[[364, 6], [48, 23]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>catboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.3, depth=3, iterations=1000</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.863946</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.360502</td>\n",
       "      <td>[[358, 12], [48, 23]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>catboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.3, depth=6, iterations=1000</td>\n",
       "      <td>0.657137</td>\n",
       "      <td>0.863946</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.386997</td>\n",
       "      <td>[[356, 14], [46, 25]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>catboost</td>\n",
       "      <td>PT adasyn</td>\n",
       "      <td>learning_rate=0.3, depth=10, iterations=1000</td>\n",
       "      <td>0.653864</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.367412</td>\n",
       "      <td>[[364, 6], [48, 23]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Description                         Parameter_Description  \\\n",
       "0    catboost   OR origin   learning_rate=0.01, depth=3, iterations=100   \n",
       "1    catboost   OR origin   learning_rate=0.01, depth=6, iterations=100   \n",
       "2    catboost   OR origin  learning_rate=0.01, depth=10, iterations=100   \n",
       "3    catboost   OR origin   learning_rate=0.01, depth=3, iterations=500   \n",
       "4    catboost   OR origin   learning_rate=0.01, depth=6, iterations=500   \n",
       "..        ...         ...                                           ...   \n",
       "157  catboost   PT adasyn    learning_rate=0.3, depth=6, iterations=500   \n",
       "158  catboost   PT adasyn   learning_rate=0.3, depth=10, iterations=500   \n",
       "159  catboost   PT adasyn   learning_rate=0.3, depth=3, iterations=1000   \n",
       "160  catboost   PT adasyn   learning_rate=0.3, depth=6, iterations=1000   \n",
       "161  catboost   PT adasyn  learning_rate=0.3, depth=10, iterations=1000   \n",
       "\n",
       "      ROC-AUC  Accuracy  Precision    Recall  F1 Score  F2 Score  \\\n",
       "0    0.512733  0.841270   0.666667  0.028169  0.054054  0.034843   \n",
       "1    0.535497  0.841270   0.545455  0.084507  0.146341  0.101695   \n",
       "2    0.528455  0.839002   0.500000  0.070423  0.123457  0.085034   \n",
       "3    0.566654  0.845805   0.578947  0.154930  0.244444  0.181518   \n",
       "4    0.573696  0.848073   0.600000  0.169014  0.263736  0.197368   \n",
       "..        ...       ...        ...       ...       ...       ...   \n",
       "157  0.665531  0.868481   0.666667  0.366197  0.472727  0.402477   \n",
       "158  0.653864  0.877551   0.793103  0.323944  0.460000  0.367412   \n",
       "159  0.645756  0.863946   0.657143  0.323944  0.433962  0.360502   \n",
       "160  0.657137  0.863946   0.641026  0.352113  0.454545  0.386997   \n",
       "161  0.653864  0.877551   0.793103  0.323944  0.460000  0.367412   \n",
       "\n",
       "          Confusion Matrix  \n",
       "0      [[369, 1], [69, 2]]  \n",
       "1      [[365, 5], [65, 6]]  \n",
       "2      [[365, 5], [66, 5]]  \n",
       "3     [[362, 8], [60, 11]]  \n",
       "4     [[362, 8], [59, 12]]  \n",
       "..                     ...  \n",
       "157  [[357, 13], [45, 26]]  \n",
       "158   [[364, 6], [48, 23]]  \n",
       "159  [[358, 12], [48, 23]]  \n",
       "160  [[356, 14], [46, 25]]  \n",
       "161   [[364, 6], [48, 23]]  \n",
       "\n",
       "[162 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Results for catboost saved to C:\\HHRR\\01_total_models\\catboost_total.csv\n"
     ]
    }
   ],
   "source": [
    "catboost_opt = gen_models_with_three_params(complete_model_list, distributions, path_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "053ff8f8-f727-42b6-80a2-4e96b3435d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_opt = catboost_opt.sort_values(by='ROC-AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ffbbad5-5b72-423d-a378-1c5e7f92583b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                                       catboost\n",
       "Description                                                 PT smote\n",
       "Parameter_Description    learning_rate=0.01, depth=3, iterations=100\n",
       "ROC-AUC                                                     0.692425\n",
       "Accuracy                                                    0.827664\n",
       "Precision                                                   0.466667\n",
       "Recall                                                      0.492958\n",
       "F1 Score                                                    0.479452\n",
       "F2 Score                                                    0.487465\n",
       "Confusion Matrix                               [[330, 40], [36, 35]]\n",
       "Name: 108, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_best = catboost_opt.iloc[0]\n",
    "catboost_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305063bf-f219-42c6-8236-b65376d8f647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
